{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN Building and Visualization Imports\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import optimizers, losses\n",
    "from keras.engine.topology import Layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Standard Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Initializations\n",
    "RF_size = 3\n",
    "stride = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pd.read_csv('binary_shapes.csv')\n",
    "inputs = inputs.drop('X1', axis = 0) # Taking out col names\n",
    "inputs = inputs.apply(pd.to_numeric)  # converting to floats\n",
    "\n",
    "inputs = inputs.values # convert to np ndarray\n",
    "inputs = inputs.reshape(955, 50, 50, 1)\n",
    "flattened_inputs = inputs.reshape(955, 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('binary_shapes_labels.csv')\n",
    "labels = labels.drop('x', axis = 0)\n",
    "labels = labels.apply(pd.to_numeric)\n",
    "labels = labels.values\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = shuffle(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 48, 48, 52)        520       \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 119808)            0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 39)                4672551   \n",
      "=================================================================\n",
      "Total params: 4,673,071\n",
      "Trainable params: 4,673,071\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape = (50,50,1), filters=52, kernel_size = RF_size, strides = stride, activation = 'relu'))\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(96, activation = 'relu'))\n",
    "model.add(Dense(39, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mod():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(input_shape = (50,50,1), filters=52, kernel_size = RF_size, strides = stride, activation = 'relu'))\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(96, activation = 'relu'))\n",
    "    model.add(Dense(39, activation = 'softmax'))\n",
    "    model.compile(optimizer = optimizers.adam(lr = 0.0005), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x = inputs, validation_split = 0.25, y = labels, batch_size = 50, epochs = 25)\n",
    "    return(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/25\n",
      "716/716 [==============================] - 6s 8ms/step - loss: 3.4380 - acc: 0.3045 - val_loss: 1.6421 - val_acc: 0.6360\n",
      "Epoch 2/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 1.0137 - acc: 0.7570 - val_loss: 0.8016 - val_acc: 0.8159\n",
      "Epoch 3/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.4649 - acc: 0.8883 - val_loss: 0.7466 - val_acc: 0.8159\n",
      "Epoch 4/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.2314 - acc: 0.9497 - val_loss: 0.6449 - val_acc: 0.8117\n",
      "Epoch 5/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.1406 - acc: 0.9749 - val_loss: 0.5677 - val_acc: 0.8326\n",
      "Epoch 6/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0782 - acc: 0.9930 - val_loss: 0.5074 - val_acc: 0.8536\n",
      "Epoch 7/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0526 - acc: 1.0000 - val_loss: 0.5263 - val_acc: 0.8410\n",
      "Epoch 8/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0369 - acc: 0.9986 - val_loss: 0.5013 - val_acc: 0.8661\n",
      "Epoch 9/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0253 - acc: 1.0000 - val_loss: 0.5019 - val_acc: 0.8494\n",
      "Epoch 10/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.5211 - val_acc: 0.8452\n",
      "Epoch 11/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.4979 - val_acc: 0.8577\n",
      "Epoch 12/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.4969 - val_acc: 0.8577\n",
      "Epoch 13/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.5132 - val_acc: 0.8577\n",
      "Epoch 14/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.5089 - val_acc: 0.8619\n",
      "Epoch 15/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.5075 - val_acc: 0.8619\n",
      "Epoch 16/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.5036 - val_acc: 0.8577\n",
      "Epoch 17/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.5098 - val_acc: 0.8661\n",
      "Epoch 18/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5103 - val_acc: 0.8619\n",
      "Epoch 19/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5114 - val_acc: 0.8661\n",
      "Epoch 20/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5147 - val_acc: 0.8661\n",
      "Epoch 21/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5115 - val_acc: 0.8661\n",
      "Epoch 22/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5199 - val_acc: 0.8661\n",
      "Epoch 23/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.5188 - val_acc: 0.8661\n",
      "Epoch 24/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.5186 - val_acc: 0.8661\n",
      "Epoch 25/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.5273 - val_acc: 0.8703\n",
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/25\n",
      "716/716 [==============================] - 6s 8ms/step - loss: 3.2638 - acc: 0.2919 - val_loss: 1.4843 - val_acc: 0.5983\n",
      "Epoch 2/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.9786 - acc: 0.7332 - val_loss: 0.8261 - val_acc: 0.7950\n",
      "Epoch 3/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.4117 - acc: 0.9120 - val_loss: 0.7357 - val_acc: 0.8033\n",
      "Epoch 4/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.2004 - acc: 0.9651 - val_loss: 0.5402 - val_acc: 0.8368\n",
      "Epoch 5/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.1095 - acc: 0.9860 - val_loss: 0.5334 - val_acc: 0.8452\n",
      "Epoch 6/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0659 - acc: 0.9958 - val_loss: 0.5210 - val_acc: 0.8410\n",
      "Epoch 7/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0420 - acc: 0.9986 - val_loss: 0.4826 - val_acc: 0.8577\n",
      "Epoch 8/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0289 - acc: 1.0000 - val_loss: 0.4856 - val_acc: 0.8452\n",
      "Epoch 9/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0208 - acc: 1.0000 - val_loss: 0.4748 - val_acc: 0.8661\n",
      "Epoch 10/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.4869 - val_acc: 0.8577\n",
      "Epoch 11/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.4768 - val_acc: 0.8619\n",
      "Epoch 12/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.4816 - val_acc: 0.8577\n",
      "Epoch 13/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.4843 - val_acc: 0.8619\n",
      "Epoch 14/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4905 - val_acc: 0.8619\n",
      "Epoch 15/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4793 - val_acc: 0.8619\n",
      "Epoch 16/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4938 - val_acc: 0.8661\n",
      "Epoch 17/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.4823 - val_acc: 0.8619\n",
      "Epoch 18/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5023 - val_acc: 0.8536\n",
      "Epoch 19/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.4915 - val_acc: 0.8661\n",
      "Epoch 20/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.4894 - val_acc: 0.8661\n",
      "Epoch 21/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5000 - val_acc: 0.8619\n",
      "Epoch 22/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.4955 - val_acc: 0.8619\n",
      "Epoch 23/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.4965 - val_acc: 0.8619\n",
      "Epoch 24/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.4985 - val_acc: 0.8619\n",
      "Epoch 25/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.5087 - val_acc: 0.8619\n",
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/25\n",
      "716/716 [==============================] - 6s 8ms/step - loss: 2.9305 - acc: 0.3226 - val_loss: 1.4159 - val_acc: 0.6067\n",
      "Epoch 2/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.8583 - acc: 0.7877 - val_loss: 0.8822 - val_acc: 0.7866\n",
      "Epoch 3/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.4290 - acc: 0.8897 - val_loss: 0.6894 - val_acc: 0.8033\n",
      "Epoch 4/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.2246 - acc: 0.9525 - val_loss: 0.5478 - val_acc: 0.8494\n",
      "Epoch 5/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.1363 - acc: 0.9804 - val_loss: 0.6537 - val_acc: 0.8075\n",
      "Epoch 6/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0765 - acc: 0.9902 - val_loss: 0.5239 - val_acc: 0.8619\n",
      "Epoch 7/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0471 - acc: 0.9958 - val_loss: 0.5214 - val_acc: 0.8368\n",
      "Epoch 8/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0316 - acc: 1.0000 - val_loss: 0.5106 - val_acc: 0.8452\n",
      "Epoch 9/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.4908 - val_acc: 0.8577\n",
      "Epoch 10/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0179 - acc: 0.9986 - val_loss: 0.5148 - val_acc: 0.8452\n",
      "Epoch 11/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.4803 - val_acc: 0.8703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.5616 - val_acc: 0.8577\n",
      "Epoch 13/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0134 - acc: 0.9986 - val_loss: 0.5053 - val_acc: 0.8619\n",
      "Epoch 14/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4983 - val_acc: 0.8619\n",
      "Epoch 15/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4992 - val_acc: 0.8661\n",
      "Epoch 16/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.5050 - val_acc: 0.8661\n",
      "Epoch 17/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5118 - val_acc: 0.8619\n",
      "Epoch 18/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.4954 - val_acc: 0.8703\n",
      "Epoch 19/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.5139 - val_acc: 0.8661\n",
      "Epoch 20/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5047 - val_acc: 0.8703\n",
      "Epoch 21/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.5034 - val_acc: 0.8661\n",
      "Epoch 22/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.5135 - val_acc: 0.8619\n",
      "Epoch 23/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.5137 - val_acc: 0.8703\n",
      "Epoch 24/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5133 - val_acc: 0.8661\n",
      "Epoch 25/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5141 - val_acc: 0.8703\n",
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/25\n",
      "716/716 [==============================] - 6s 8ms/step - loss: 2.9588 - acc: 0.3408 - val_loss: 1.6322 - val_acc: 0.6234\n",
      "Epoch 2/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.9881 - acc: 0.7374 - val_loss: 0.9036 - val_acc: 0.7866\n",
      "Epoch 3/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.4239 - acc: 0.9120 - val_loss: 0.6289 - val_acc: 0.8410\n",
      "Epoch 4/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.2342 - acc: 0.9441 - val_loss: 0.6103 - val_acc: 0.8201\n",
      "Epoch 5/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.1446 - acc: 0.9679 - val_loss: 0.6294 - val_acc: 0.8117\n",
      "Epoch 6/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.1017 - acc: 0.9818 - val_loss: 0.5241 - val_acc: 0.8410\n",
      "Epoch 7/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0564 - acc: 0.9888 - val_loss: 0.5084 - val_acc: 0.8619\n",
      "Epoch 8/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0266 - acc: 0.9986 - val_loss: 0.5003 - val_acc: 0.8494\n",
      "Epoch 9/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.5310 - val_acc: 0.8661\n",
      "Epoch 10/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0172 - acc: 0.9972 - val_loss: 0.5011 - val_acc: 0.8536\n",
      "Epoch 11/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.4974 - val_acc: 0.8661\n",
      "Epoch 12/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.4986 - val_acc: 0.8619\n",
      "Epoch 13/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4997 - val_acc: 0.8619\n",
      "Epoch 14/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4936 - val_acc: 0.8619\n",
      "Epoch 15/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.4992 - val_acc: 0.8619\n",
      "Epoch 16/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.5069 - val_acc: 0.8619\n",
      "Epoch 17/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5048 - val_acc: 0.8619\n",
      "Epoch 18/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5053 - val_acc: 0.8619\n",
      "Epoch 19/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5067 - val_acc: 0.8619\n",
      "Epoch 20/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.5091 - val_acc: 0.8661\n",
      "Epoch 21/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.5129 - val_acc: 0.8703\n",
      "Epoch 22/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.5054 - val_acc: 0.8619\n",
      "Epoch 23/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.5205 - val_acc: 0.8536\n",
      "Epoch 24/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.5203 - val_acc: 0.8661\n",
      "Epoch 25/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5240 - val_acc: 0.8577\n",
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/25\n",
      "716/716 [==============================] - 6s 8ms/step - loss: 2.8563 - acc: 0.3380 - val_loss: 1.6012 - val_acc: 0.5690\n",
      "Epoch 2/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.8705 - acc: 0.7919 - val_loss: 0.8330 - val_acc: 0.7950\n",
      "Epoch 3/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.4080 - acc: 0.8994 - val_loss: 0.7120 - val_acc: 0.7992\n",
      "Epoch 4/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.1881 - acc: 0.9637 - val_loss: 0.5845 - val_acc: 0.8452\n",
      "Epoch 5/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.1010 - acc: 0.9832 - val_loss: 0.5298 - val_acc: 0.8536\n",
      "Epoch 6/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0545 - acc: 0.9944 - val_loss: 0.5234 - val_acc: 0.8577\n",
      "Epoch 7/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0305 - acc: 1.0000 - val_loss: 0.4777 - val_acc: 0.8577\n",
      "Epoch 8/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0229 - acc: 1.0000 - val_loss: 0.5677 - val_acc: 0.8410\n",
      "Epoch 9/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0190 - acc: 1.0000 - val_loss: 0.5058 - val_acc: 0.8577\n",
      "Epoch 10/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.5121 - val_acc: 0.8661\n",
      "Epoch 11/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.5041 - val_acc: 0.8703\n",
      "Epoch 12/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4988 - val_acc: 0.8619\n",
      "Epoch 13/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.5093 - val_acc: 0.8661\n",
      "Epoch 14/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.5178 - val_acc: 0.8619\n",
      "Epoch 15/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.4993 - val_acc: 0.8703\n",
      "Epoch 16/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5127 - val_acc: 0.8619\n",
      "Epoch 17/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5077 - val_acc: 0.8619\n",
      "Epoch 18/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5133 - val_acc: 0.8619\n",
      "Epoch 19/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.5215 - val_acc: 0.8619\n",
      "Epoch 20/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.5139 - val_acc: 0.8619\n",
      "Epoch 21/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.5229 - val_acc: 0.8661\n",
      "Epoch 22/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5189 - val_acc: 0.8703\n",
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5229 - val_acc: 0.8661\n",
      "Epoch 24/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5270 - val_acc: 0.8661\n",
      "Epoch 25/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5210 - val_acc: 0.8661\n",
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/25\n",
      "716/716 [==============================] - 6s 8ms/step - loss: 3.3171 - acc: 0.2989 - val_loss: 1.6426 - val_acc: 0.5732\n",
      "Epoch 2/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 1.0634 - acc: 0.7542 - val_loss: 0.9919 - val_acc: 0.7531\n",
      "Epoch 3/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.4808 - acc: 0.8841 - val_loss: 0.6340 - val_acc: 0.8410\n",
      "Epoch 4/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.2462 - acc: 0.9469 - val_loss: 0.5660 - val_acc: 0.8452\n",
      "Epoch 5/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.1375 - acc: 0.9679 - val_loss: 0.6231 - val_acc: 0.8033\n",
      "Epoch 6/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0850 - acc: 0.9888 - val_loss: 0.5209 - val_acc: 0.8243\n",
      "Epoch 7/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0485 - acc: 0.9916 - val_loss: 0.4961 - val_acc: 0.8285\n",
      "Epoch 8/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0305 - acc: 1.0000 - val_loss: 0.4748 - val_acc: 0.8619\n",
      "Epoch 9/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0213 - acc: 1.0000 - val_loss: 0.4616 - val_acc: 0.8703\n",
      "Epoch 10/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.4657 - val_acc: 0.8745\n",
      "Epoch 11/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.4698 - val_acc: 0.8619\n",
      "Epoch 12/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.4673 - val_acc: 0.8703\n",
      "Epoch 13/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.4765 - val_acc: 0.8619\n",
      "Epoch 14/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4690 - val_acc: 0.8703\n",
      "Epoch 15/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4743 - val_acc: 0.8703\n",
      "Epoch 16/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4734 - val_acc: 0.8745\n",
      "Epoch 17/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.4760 - val_acc: 0.8745\n",
      "Epoch 18/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.4753 - val_acc: 0.8745\n",
      "Epoch 19/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.4866 - val_acc: 0.8703\n",
      "Epoch 20/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.4842 - val_acc: 0.8745\n",
      "Epoch 21/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.4792 - val_acc: 0.8745\n",
      "Epoch 22/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.4794 - val_acc: 0.8745\n",
      "Epoch 23/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.4921 - val_acc: 0.8787\n",
      "Epoch 24/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.4936 - val_acc: 0.8745\n",
      "Epoch 25/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.4870 - val_acc: 0.8745\n",
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/25\n",
      "716/716 [==============================] - 6s 8ms/step - loss: 3.1408 - acc: 0.3017 - val_loss: 1.5918 - val_acc: 0.5690\n",
      "Epoch 2/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.9462 - acc: 0.7737 - val_loss: 0.8099 - val_acc: 0.7950\n",
      "Epoch 3/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.4291 - acc: 0.8911 - val_loss: 0.6772 - val_acc: 0.8326\n",
      "Epoch 4/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.2102 - acc: 0.9581 - val_loss: 0.6202 - val_acc: 0.8159\n",
      "Epoch 5/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.1322 - acc: 0.9721 - val_loss: 0.5840 - val_acc: 0.8117\n",
      "Epoch 6/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0807 - acc: 0.9860 - val_loss: 0.5067 - val_acc: 0.8536\n",
      "Epoch 7/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0433 - acc: 1.0000 - val_loss: 0.5739 - val_acc: 0.8285\n",
      "Epoch 8/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0282 - acc: 1.0000 - val_loss: 0.4760 - val_acc: 0.8577\n",
      "Epoch 9/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.5009 - val_acc: 0.8494\n",
      "Epoch 10/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.4817 - val_acc: 0.8619\n",
      "Epoch 11/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.5003 - val_acc: 0.8452\n",
      "Epoch 12/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.4845 - val_acc: 0.8619\n",
      "Epoch 13/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4979 - val_acc: 0.8536\n",
      "Epoch 14/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4891 - val_acc: 0.8536\n",
      "Epoch 15/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4980 - val_acc: 0.8494\n",
      "Epoch 16/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.5030 - val_acc: 0.8536\n",
      "Epoch 17/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.4982 - val_acc: 0.8577\n",
      "Epoch 18/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.4977 - val_acc: 0.8536\n",
      "Epoch 19/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.4971 - val_acc: 0.8577\n",
      "Epoch 20/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.5006 - val_acc: 0.8577\n",
      "Epoch 21/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.5044 - val_acc: 0.8536\n",
      "Epoch 22/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.5063 - val_acc: 0.8577\n",
      "Epoch 23/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5028 - val_acc: 0.8619\n",
      "Epoch 24/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5122 - val_acc: 0.8536\n",
      "Epoch 25/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5035 - val_acc: 0.8536\n",
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/25\n",
      "716/716 [==============================] - 6s 8ms/step - loss: 3.3890 - acc: 0.3352 - val_loss: 1.6328 - val_acc: 0.5481\n",
      "Epoch 2/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.9437 - acc: 0.7416 - val_loss: 0.9647 - val_acc: 0.7113\n",
      "Epoch 3/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.4012 - acc: 0.8869 - val_loss: 0.7175 - val_acc: 0.7908\n",
      "Epoch 4/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.2281 - acc: 0.9567 - val_loss: 0.6469 - val_acc: 0.8201\n",
      "Epoch 5/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.1302 - acc: 0.9735 - val_loss: 0.6300 - val_acc: 0.8117\n",
      "Epoch 6/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0904 - acc: 0.9888 - val_loss: 0.5548 - val_acc: 0.8410\n",
      "Epoch 7/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0535 - acc: 0.9958 - val_loss: 0.5046 - val_acc: 0.8285\n",
      "Epoch 8/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0303 - acc: 0.9986 - val_loss: 0.5095 - val_acc: 0.8368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0225 - acc: 0.9986 - val_loss: 0.5022 - val_acc: 0.8577\n",
      "Epoch 10/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.4928 - val_acc: 0.8619\n",
      "Epoch 11/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.5081 - val_acc: 0.8577\n",
      "Epoch 12/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.5045 - val_acc: 0.8452\n",
      "Epoch 13/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.5109 - val_acc: 0.8577\n",
      "Epoch 14/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.5066 - val_acc: 0.8577\n",
      "Epoch 15/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.5038 - val_acc: 0.8661\n",
      "Epoch 16/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.5076 - val_acc: 0.8619\n",
      "Epoch 17/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.5066 - val_acc: 0.8619\n",
      "Epoch 18/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5244 - val_acc: 0.8536\n",
      "Epoch 19/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5096 - val_acc: 0.8619\n",
      "Epoch 20/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.5154 - val_acc: 0.8661\n",
      "Epoch 21/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.5140 - val_acc: 0.8619\n",
      "Epoch 22/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.5216 - val_acc: 0.8619\n",
      "Epoch 23/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.5164 - val_acc: 0.8619\n",
      "Epoch 24/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.5253 - val_acc: 0.8619\n",
      "Epoch 25/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5291 - val_acc: 0.8577\n",
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/25\n",
      "716/716 [==============================] - 6s 8ms/step - loss: 3.1013 - acc: 0.3226 - val_loss: 1.6439 - val_acc: 0.6234\n",
      "Epoch 2/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.9198 - acc: 0.7654 - val_loss: 0.9143 - val_acc: 0.7406\n",
      "Epoch 3/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.4180 - acc: 0.9162 - val_loss: 0.6656 - val_acc: 0.7992\n",
      "Epoch 4/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.2235 - acc: 0.9525 - val_loss: 0.6084 - val_acc: 0.8410\n",
      "Epoch 5/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.1218 - acc: 0.9791 - val_loss: 0.5855 - val_acc: 0.8326\n",
      "Epoch 6/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0743 - acc: 0.9888 - val_loss: 0.6360 - val_acc: 0.7992\n",
      "Epoch 7/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0508 - acc: 0.9930 - val_loss: 0.5593 - val_acc: 0.8285\n",
      "Epoch 8/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0367 - acc: 0.9972 - val_loss: 0.5230 - val_acc: 0.8452\n",
      "Epoch 9/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0273 - acc: 0.9986 - val_loss: 0.5282 - val_acc: 0.8326\n",
      "Epoch 10/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0182 - acc: 0.9986 - val_loss: 0.4918 - val_acc: 0.8619\n",
      "Epoch 11/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.4962 - val_acc: 0.8577\n",
      "Epoch 12/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.5255 - val_acc: 0.8619\n",
      "Epoch 13/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.5046 - val_acc: 0.8619\n",
      "Epoch 14/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.5044 - val_acc: 0.8619\n",
      "Epoch 15/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.5187 - val_acc: 0.8577\n",
      "Epoch 16/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.5045 - val_acc: 0.8619\n",
      "Epoch 17/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.5115 - val_acc: 0.8577\n",
      "Epoch 18/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.5034 - val_acc: 0.8661\n",
      "Epoch 19/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5253 - val_acc: 0.8536\n",
      "Epoch 20/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.5147 - val_acc: 0.8577\n",
      "Epoch 21/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.5171 - val_acc: 0.8619\n",
      "Epoch 22/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.5264 - val_acc: 0.8619\n",
      "Epoch 23/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.5212 - val_acc: 0.8619\n",
      "Epoch 24/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.5262 - val_acc: 0.8619\n",
      "Epoch 25/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5224 - val_acc: 0.8577\n",
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/25\n",
      "716/716 [==============================] - 6s 8ms/step - loss: 2.9112 - acc: 0.3408 - val_loss: 1.5583 - val_acc: 0.6234\n",
      "Epoch 2/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.9199 - acc: 0.7961 - val_loss: 0.9564 - val_acc: 0.7280\n",
      "Epoch 3/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.4174 - acc: 0.8911 - val_loss: 0.6850 - val_acc: 0.7866\n",
      "Epoch 4/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.2420 - acc: 0.9413 - val_loss: 0.6757 - val_acc: 0.7866\n",
      "Epoch 5/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.1211 - acc: 0.9791 - val_loss: 0.5493 - val_acc: 0.8285\n",
      "Epoch 6/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0699 - acc: 0.9930 - val_loss: 0.5072 - val_acc: 0.8536\n",
      "Epoch 7/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0406 - acc: 0.9986 - val_loss: 0.5287 - val_acc: 0.8410\n",
      "Epoch 8/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0266 - acc: 1.0000 - val_loss: 0.4947 - val_acc: 0.8577\n",
      "Epoch 9/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.4954 - val_acc: 0.8494\n",
      "Epoch 10/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.5048 - val_acc: 0.8577\n",
      "Epoch 11/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.4970 - val_acc: 0.8577\n",
      "Epoch 12/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.4956 - val_acc: 0.8536\n",
      "Epoch 13/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.5011 - val_acc: 0.8536\n",
      "Epoch 14/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.5047 - val_acc: 0.8577\n",
      "Epoch 15/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.5009 - val_acc: 0.8661\n",
      "Epoch 16/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.5048 - val_acc: 0.8619\n",
      "Epoch 17/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.5096 - val_acc: 0.8619\n",
      "Epoch 18/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5129 - val_acc: 0.8577\n",
      "Epoch 19/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5215 - val_acc: 0.8577\n",
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5079 - val_acc: 0.8619\n",
      "Epoch 21/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.5173 - val_acc: 0.8619\n",
      "Epoch 22/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.5178 - val_acc: 0.8619\n",
      "Epoch 23/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.5165 - val_acc: 0.8661\n",
      "Epoch 24/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5126 - val_acc: 0.8619\n",
      "Epoch 25/25\n",
      "716/716 [==============================] - 5s 6ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5208 - val_acc: 0.8661\n",
      "acc15 = 0.8238493707888296 \n",
      " acc100 = 0.8635983255119004 \n",
      " loss15 = 0.5885942238893469 \n",
      " loss100 = 0.5157839598017258\n"
     ]
    }
   ],
   "source": [
    "val_acc5 = np.zeros(10)\n",
    "val_acc25 = np.zeros(10)\n",
    "val_loss5 = np.zeros(10)\n",
    "val_loss25 = np.zeros(10)\n",
    "for i in range(10):\n",
    "        results = run_mod()\n",
    "        val_acc5[i] = results.history['val_acc'][4]\n",
    "        val_acc25[i] = results.history['val_acc'][24]\n",
    "        val_loss5[i] = results.history['val_loss'][4]\n",
    "        val_loss25[i] = results.history['val_loss'][24]\n",
    "        \n",
    "print(\"acc15 = \" + str(np.mean(val_acc5)), \"\\n\",\n",
    "      \"acc100 = \" + str(np.mean(val_acc25)), \"\\n\",\n",
    "      \"loss15 = \" + str(np.mean(val_loss5)), \"\\n\",\n",
    "     \"loss100 = \" + str(np.mean(val_loss25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27698aba710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27698b292e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "* make sure image set MI caluclations for binary shapes datasets are right its doing it for all 955 with 2*2 clusters \n",
    "* for 8x8 the filter you have to learn is more complex but eventually its more efficient, maybe thats why loss is less for 2x2 at 15 epochs\n",
    "* Also more paramters to tune with larger RF size, but same LR and same # of epochs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/100\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 3.3994 - acc: 0.1536 - val_loss: 3.0667 - val_acc: 0.2720\n",
      "Epoch 2/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 2.5525 - acc: 0.4302 - val_loss: 2.6166 - val_acc: 0.4059\n",
      "Epoch 3/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 1.9698 - acc: 0.5293 - val_loss: 2.2005 - val_acc: 0.4561\n",
      "Epoch 4/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 1.4676 - acc: 0.6606 - val_loss: 1.7521 - val_acc: 0.5523\n",
      "Epoch 5/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 1.0326 - acc: 0.7835 - val_loss: 1.4461 - val_acc: 0.6653\n",
      "Epoch 6/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.7769 - acc: 0.8408 - val_loss: 1.2441 - val_acc: 0.6778\n",
      "Epoch 7/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.6285 - acc: 0.8659 - val_loss: 1.1151 - val_acc: 0.7113\n",
      "Epoch 8/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.5125 - acc: 0.8771 - val_loss: 0.9741 - val_acc: 0.7448\n",
      "Epoch 9/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.4346 - acc: 0.8869 - val_loss: 0.9739 - val_acc: 0.7615\n",
      "Epoch 10/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.3977 - acc: 0.9008 - val_loss: 0.9163 - val_acc: 0.7197\n",
      "Epoch 11/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.2876 - acc: 0.9441 - val_loss: 0.7789 - val_acc: 0.7741\n",
      "Epoch 12/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.2376 - acc: 0.9511 - val_loss: 0.8409 - val_acc: 0.7699\n",
      "Epoch 13/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.2042 - acc: 0.9595 - val_loss: 0.8611 - val_acc: 0.7657\n",
      "Epoch 14/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.1637 - acc: 0.9749 - val_loss: 0.7522 - val_acc: 0.8159\n",
      "Epoch 15/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.1200 - acc: 0.9860 - val_loss: 0.7149 - val_acc: 0.7992\n",
      "Epoch 16/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0939 - acc: 0.9874 - val_loss: 0.6700 - val_acc: 0.8159\n",
      "Epoch 17/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0877 - acc: 0.9930 - val_loss: 0.6791 - val_acc: 0.8159\n",
      "Epoch 18/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0697 - acc: 0.9972 - val_loss: 0.7209 - val_acc: 0.8159\n",
      "Epoch 19/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0666 - acc: 0.9930 - val_loss: 0.7095 - val_acc: 0.8075\n",
      "Epoch 20/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0519 - acc: 0.9986 - val_loss: 0.6990 - val_acc: 0.8117\n",
      "Epoch 21/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0438 - acc: 1.0000 - val_loss: 0.6558 - val_acc: 0.8494\n",
      "Epoch 22/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0392 - acc: 0.9986 - val_loss: 0.6333 - val_acc: 0.8326\n",
      "Epoch 23/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0394 - acc: 1.0000 - val_loss: 0.6656 - val_acc: 0.8201\n",
      "Epoch 24/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0507 - acc: 0.9916 - val_loss: 0.7094 - val_acc: 0.8075\n",
      "Epoch 25/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0390 - acc: 0.9986 - val_loss: 0.6745 - val_acc: 0.8368\n",
      "Epoch 26/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0437 - acc: 0.9902 - val_loss: 0.6573 - val_acc: 0.8159\n",
      "Epoch 27/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0446 - acc: 0.9916 - val_loss: 0.6963 - val_acc: 0.8033\n",
      "Epoch 28/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0281 - acc: 0.9958 - val_loss: 0.6506 - val_acc: 0.8452\n",
      "Epoch 29/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.6472 - val_acc: 0.8368\n",
      "Epoch 30/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0193 - acc: 0.9986 - val_loss: 0.6841 - val_acc: 0.8326\n",
      "Epoch 31/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0159 - acc: 1.0000 - val_loss: 0.6442 - val_acc: 0.8452\n",
      "Epoch 32/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.6562 - val_acc: 0.8410\n",
      "Epoch 33/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.6527 - val_acc: 0.8452\n",
      "Epoch 34/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.6430 - val_acc: 0.8452\n",
      "Epoch 35/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.6442 - val_acc: 0.8368\n",
      "Epoch 36/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.6594 - val_acc: 0.8410\n",
      "Epoch 37/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.6619 - val_acc: 0.8452\n",
      "Epoch 38/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.6504 - val_acc: 0.8494\n",
      "Epoch 39/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.6601 - val_acc: 0.8368\n",
      "Epoch 40/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.6541 - val_acc: 0.8452\n",
      "Epoch 41/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.6662 - val_acc: 0.8410\n",
      "Epoch 42/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.6454 - val_acc: 0.8536\n",
      "Epoch 43/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.6610 - val_acc: 0.8410\n",
      "Epoch 44/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.6596 - val_acc: 0.8494\n",
      "Epoch 45/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.6685 - val_acc: 0.8410\n",
      "Epoch 46/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.6578 - val_acc: 0.8410\n",
      "Epoch 47/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.6571 - val_acc: 0.8452\n",
      "Epoch 48/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.6583 - val_acc: 0.8536\n",
      "Epoch 49/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.6626 - val_acc: 0.8452\n",
      "Epoch 50/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.6600 - val_acc: 0.8494\n",
      "Epoch 51/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.6682 - val_acc: 0.8410\n",
      "Epoch 52/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.6674 - val_acc: 0.8452\n",
      "Epoch 53/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.6665 - val_acc: 0.8494\n",
      "Epoch 54/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.6726 - val_acc: 0.8452\n",
      "Epoch 55/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.6715 - val_acc: 0.8452\n",
      "Epoch 56/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.6713 - val_acc: 0.8410\n",
      "Epoch 57/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.6805 - val_acc: 0.8452\n",
      "Epoch 58/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.6770 - val_acc: 0.8536\n",
      "Epoch 59/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.6738 - val_acc: 0.8494\n",
      "Epoch 60/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.6806 - val_acc: 0.8452\n",
      "Epoch 61/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6782 - val_acc: 0.8410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6816 - val_acc: 0.8494\n",
      "Epoch 63/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6897 - val_acc: 0.8452\n",
      "Epoch 64/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6787 - val_acc: 0.8452\n",
      "Epoch 65/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.7076 - val_acc: 0.8452\n",
      "Epoch 66/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6768 - val_acc: 0.8452\n",
      "Epoch 67/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6867 - val_acc: 0.8536\n",
      "Epoch 68/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6932 - val_acc: 0.8452\n",
      "Epoch 69/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6719 - val_acc: 0.8536\n",
      "Epoch 70/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6940 - val_acc: 0.8494\n",
      "Epoch 71/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.6832 - val_acc: 0.8494\n",
      "Epoch 72/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.7293 - val_acc: 0.8494\n",
      "Epoch 73/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6856 - val_acc: 0.8494\n",
      "Epoch 74/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.7007 - val_acc: 0.8536\n",
      "Epoch 75/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6902 - val_acc: 0.8536\n",
      "Epoch 76/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6948 - val_acc: 0.8452\n",
      "Epoch 77/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6946 - val_acc: 0.8536\n",
      "Epoch 78/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6928 - val_acc: 0.8410\n",
      "Epoch 79/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.7044 - val_acc: 0.8494\n",
      "Epoch 80/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6939 - val_acc: 0.8536\n",
      "Epoch 81/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6969 - val_acc: 0.8536\n",
      "Epoch 82/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.7012 - val_acc: 0.8536\n",
      "Epoch 83/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.7031 - val_acc: 0.8536\n",
      "Epoch 84/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.7047 - val_acc: 0.8494\n",
      "Epoch 85/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.7071 - val_acc: 0.8536\n",
      "Epoch 86/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.7022 - val_acc: 0.8536\n",
      "Epoch 87/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.7088 - val_acc: 0.8536\n",
      "Epoch 88/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.7008 - val_acc: 0.8536\n",
      "Epoch 89/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.7007 - val_acc: 0.8536\n",
      "Epoch 90/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.7060 - val_acc: 0.8536\n",
      "Epoch 91/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.7065 - val_acc: 0.8536\n",
      "Epoch 92/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.7113 - val_acc: 0.8536\n",
      "Epoch 93/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.7021 - val_acc: 0.8536\n",
      "Epoch 94/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.7098 - val_acc: 0.8536\n",
      "Epoch 95/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.7115 - val_acc: 0.8536\n",
      "Epoch 96/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.7134 - val_acc: 0.8536\n",
      "Epoch 97/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.7090 - val_acc: 0.8536\n",
      "Epoch 98/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.7152 - val_acc: 0.8536\n",
      "Epoch 99/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.7130 - val_acc: 0.8536\n",
      "Epoch 100/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.7112 - val_acc: 0.8536\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape = (50,50,1), filters=52, kernel_size = RF_size, strides = stride, activation = 'relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(96, activation = 'relu'))\n",
    "model.add(Dense(39, activation = 'softmax'))\n",
    "model.compile(optimizer = optimizers.adam(lr = 0.0005), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x = inputs, validation_split = 0.25, y = labels, batch_size = 50, epochs = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
