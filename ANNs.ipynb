{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing and Running ANNs for RF Mutual Information Investigation\n",
    "## Thomas Possidente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Value Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN Building Imports\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.engine.topology import Layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "\n",
    "# Standard Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Value Inits - Specify as needed\n",
    "num_inputs_per_batch = int(1000)  # number of dummy images in set\n",
    "size = int(16)          # Dimension of each dummy image should be size*size\n",
    "RF_size = int(2)        # Dimensions of the RF to be analyzed should be RF_size*RF_size\n",
    "\n",
    "# Value Inits - Leave these alone\n",
    "num_of_RFs = int((size*size) / (RF_size*RF_size))\n",
    "inputs_by_RF = np.empty([(num_inputs_per_batch * size), size])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1280000 into shape (1000,16,16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0d797dcb3d10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;31m# convert to np ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# reshape to desired dims (1000 examples, 16*16)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1280000 into shape (1000,16,16)"
     ]
    }
   ],
   "source": [
    "inputs = pd.read_csv('test.csv')\n",
    "inputs = inputs.drop('X1', axis = 0) # Taking out col names\n",
    "inputs = inputs.apply(pd.to_numeric)  # converting to floats\n",
    "\n",
    "inputs = inputs.values # convert to np ndarray\n",
    "inputs = inputs.reshape(1000,16,16) # reshape to desired dims (1000 examples, 16*16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through num_inputs and extract each RF input, flatten, and store in ndarray\n",
    "\n",
    "origin_x = 0\n",
    "origin_y = 0\n",
    "count = 0\n",
    "\n",
    "for n in range(0, num_of_RFs): # For each RF field in dummy image\n",
    "    for i in range(0, num_inputs_per_batch): # For each dummy image in set\n",
    "        single_RF_input = inputs[i, origin_y:(origin_y + RF_size), origin_x:(origin_x + RF_size)] # Extract 1 RF \n",
    "        single_RF_input_flat = single_RF_input.reshape((RF_size*RF_size)) \n",
    "        inputs_by_RF[count,] = single_RF_input_flat \n",
    "        count += 1\n",
    "    if(origin_x == (size - RF_size)):  # Changes RF field over image\n",
    "        origin_x = 0\n",
    "        origin_y += RF_size\n",
    "    else:\n",
    "        origin_x += RF_size\n",
    "        \n",
    "inputs_by_RF = inputs_by_RF.reshape(num_of_RFs, num_inputs_per_batch, (RF_size*RF_size)) \n",
    "# ^Reshaping to (RF Location, Image number, flattened RF) - this makes it easier to select inputs for each separate ANN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "class Hebbian(Layer):\n",
    "    \n",
    "    \n",
    "    def __init__(self, output_dim, lmbda=1.0, eta=0.005, winners = 1, connectivity='random', connectivity_prob=0.25, **kwargs):\n",
    "        '''\n",
    "        Constructor for the Hebbian learning layer.\n",
    "\n",
    "        args:\n",
    "            output_dim - The shape of the output / activations computed by the layer.\n",
    "            lambda - A floating-point valued parameter governing the strength of the Hebbian learning activation.\n",
    "            eta - A floating-point valued parameter governing the Hebbian learning rate.\n",
    "            winners - number of output nodes that should \"win\"/become activated in winner-take-all activation\n",
    "            connectivity - A string which determines the way in which the neurons in this layer are connected to\n",
    "                the neurons in the previous layer.\n",
    "        '''\n",
    "        self.output_dim = output_dim\n",
    "        self.lmbda = lmbda\n",
    "        self.eta = eta\n",
    "        self.connectivity = connectivity\n",
    "        self.connectivity_prob = connectivity_prob\n",
    "\n",
    "        super(Hebbian, self).__init__(**kwargs)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def random_conn_init(self, shape, dtype=None):\n",
    "        A = np.random.normal(0, 1, shape)\n",
    "        A[self.B] = 0\n",
    "        return tf.constant(A, dtype=tf.float32)\n",
    "\n",
    "\n",
    "    def zero_init(self, shape, dtype=None):\n",
    "        return np.zeros(shape)\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # create weight variable for this layer according to user-specified initialization\n",
    "        if self.connectivity == 'random':\n",
    "            self.B = np.random.random(input_shape[0]) < self.connectivity_prob\n",
    "        elif self.connectivity == 'zero':\n",
    "            self.B = np.zeros(self.output_dim)\n",
    "            \n",
    "        if self.connectivity == 'all':\n",
    "            self.kernel = self.add_weight(name='kernel', shape=(np.prod(input_shape[1:]), \\\n",
    "                        np.prod(self.output_dim)), initializer='uniform', trainable=False)\n",
    "        elif self.connectivity == 'random':\n",
    "            self.kernel = self.add_weight(name='kernel', shape=(np.prod(input_shape[1:]), \\\n",
    "                        np.prod(self.output_dim)), initializer=self.random_conn_init, trainable=False)\n",
    "        elif self.connectivity == 'zero':\n",
    "            self.kernel = self.add_weight(name='kernel', shape=(np.prod(input_shape[1:]), \\\n",
    "                        np.prod(self.output_dim)), initializer=self.zero_init, trainable=False)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "\n",
    "        # call superclass \"build\" function\n",
    "        super(Hebbian, self).build(input_shape)\n",
    "\n",
    "\n",
    "    def call(self, x):  # x is the input to the network\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        x_shape = tf.shape(x)\n",
    "\n",
    "        # reshape to (batch_size, product of other dimensions) shape\n",
    "        x = tf.reshape(x, (batch_size, tf.reduce_prod(x_shape[1:])))\n",
    "\n",
    "        # compute activations using Hebbian-like update rule\n",
    "        pre_activations = self.lmbda * tf.matmul(x, self.kernel)\n",
    "\n",
    "        # Should implement winner-takes-all on activations here\n",
    "        \n",
    "        numpy_activations = np.zeros((num_inputs_per_batch, self.output_dim))\n",
    "        \n",
    "        for n in range(0, num_inputs_per_batch):\n",
    "            numpy_activation_slice = pre_activations[[n]].eval(session = sess)\n",
    "            indices_max = np.argsort(-numpy_activation_slice)[:winners]\n",
    "            numpy_activation_slice = numpy_activation_slice * 0\n",
    "            numpy_activation_slice[indices_max] = 1\n",
    "            numpy_activations[n] = numpy_activation_slice\n",
    "            \n",
    "        activations = tf.convert_to_tensor(numpy_activations)\n",
    "                    \n",
    "        # do it all with tensors - use softmax function with parameter to make everything 0 exept for one value\n",
    "            #ind = tf.equal(h, tf.reduce_max(h, axis=2, keep_dims=True))\n",
    "            #return tf.multiply(h, tf.cast(ind, h.dtype))\n",
    "            \n",
    "        #    for x in range(0, tf.shape(activations[[n]])):\n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        #activations = x + self.lmbda * tf.matmul(self.kernel, x)  # why \"x +\", should this be removed? \n",
    "                                                                  # Matrix Multiplication will give us the activations\n",
    "                                                                  # so why add the input to the activation? This shouldn't\n",
    "                                                                  # even work bc the dims of x are different than\n",
    "                                                                  # the dims of tf.matmul(kernal, x)\n",
    "\n",
    "        # compute outer product of activations matrix with itself\n",
    "            # outer_product = tf.matmul(tf.expand_dims(x, 1), tf.expand_dims(x, 0))  # No idea why you would compute outer prod \n",
    "                                                                               # of inputs w/ itself. This method of weight \n",
    "                                                                               # updating seems wrong for our purposes\n",
    "                    \n",
    "         # update the weight matrix of this layer\n",
    "            # self.kernel = self.kernel + tf.multiply(self.eta, tf.reduce_mean(outer_product, axis=2)) # Still why outer prod?\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "                    \n",
    "        # Loop through each input and update weights via hebbian update\n",
    "        for i in range(0, num_inputs_per_batch):  \n",
    "            input_set_1 = x[[i]] # select one input\n",
    "            input_set = tf.tile(input_set_1, [tf.shape(self.kernel)[1]]) # repeat input\n",
    "            input_set = tf.reshape(input_set, [tf.shape(self.kernel)[1], tf.shape(self.kernel)[0]]) # reshape to transpose of kernal shape\n",
    "            input_set = tf.transpose(input_set) # transpose\n",
    "            self.kernel = self.kernel\n",
    "            #+ (self.eta * (input_set - self.kernel) * activations[[i]]) # weight update based on Hebb's Rule\n",
    "            # will likely have to build this update into a custom optimization function\n",
    "       \n",
    "        #self.kernel = tf.multiply(self.kernel, self.B) # zeroing node connections that started at 0\n",
    "        return K.reshape(activations, (batch_size, self.output_dim))\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "### Scrap Page ###\n",
    "pre_activations = tf.random_uniform(shape = [1000,4], minval = 0, maxval = 1)\n",
    "numpy_activations = np.zeros((1000,4))\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    numpy_activations_slice = np.array(pre_activations[[0]])\n",
    "    indices_max = np.argsort(-numpy_activations_slice)[:3]\n",
    "    #numpy_activations_slice = numpy_activations_slice * 0\n",
    "    #numpy_activations_slice[indices_max] = 1\n",
    "    #numpy_activations[0] = numpy_activations_slice\n",
    "    #activations = tf.convert_to_tensor(numpy_activations)\n",
    "    print(indices_max)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'hebbian_4_input' with dtype float and shape [?,1,16]\n\t [[Node: hebbian_4_input = Placeholder[dtype=DT_FLOAT, shape=[?,1,16], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'hebbian_4_input', defined at:\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-50-ab729f9cd829>\", line 2, in <module>\n    model.add(Hebbian(input_shape = (1, (RF_size*RF_size)), output_dim = 4, eta = 0.05, winners = 1))\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\keras\\models.py\", line 493, in add\n    name=layer.name + '_input')\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\", line 1457, in Input\n    input_tensor=tensor)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\", line 1366, in __init__\n    name=self.name)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 508, in placeholder\n    x = tf.placeholder(dtype, shape=shape, name=name)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1808, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5835, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'hebbian_4_input' with dtype float and shape [?,1,16]\n\t [[Node: hebbian_4_input = Placeholder[dtype=DT_FLOAT, shape=[?,1,16], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'hebbian_4_input' with dtype float and shape [?,1,16]\n\t [[Node: hebbian_4_input = Placeholder[dtype=DT_FLOAT, shape=[?,1,16], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-ab729f9cd829>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHebbian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mRF_size\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mRF_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwinners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m                 \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m                 \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-742feabcadcb>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_inputs_per_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[0mnumpy_activation_slice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpre_activations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m             \u001b[0mindices_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnumpy_activation_slice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mwinners\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mnumpy_activation_slice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy_activation_slice\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m     \"\"\"\n\u001b[1;32m--> 710\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   5178\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5179\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 5180\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'hebbian_4_input' with dtype float and shape [?,1,16]\n\t [[Node: hebbian_4_input = Placeholder[dtype=DT_FLOAT, shape=[?,1,16], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'hebbian_4_input', defined at:\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-50-ab729f9cd829>\", line 2, in <module>\n    model.add(Hebbian(input_shape = (1, (RF_size*RF_size)), output_dim = 4, eta = 0.05, winners = 1))\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\keras\\models.py\", line 493, in add\n    name=layer.name + '_input')\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\", line 1457, in Input\n    input_tensor=tensor)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\", line 1366, in __init__\n    name=self.name)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 508, in placeholder\n    x = tf.placeholder(dtype, shape=shape, name=name)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1808, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5835, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'hebbian_4_input' with dtype float and shape [?,1,16]\n\t [[Node: hebbian_4_input = Placeholder[dtype=DT_FLOAT, shape=[?,1,16], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Hebbian(input_shape = (1, (RF_size*RF_size)), output_dim = 4, eta = 0.05, winners = 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_loss(y_true, y_pred): return y_pred             \n",
    "\n",
    "class dummy_opt(keras.optimizers.Optimizer): \n",
    "    def __init__(self): return(None)\n",
    "    def get_updates(self, loss, params): return(np.array(1))\n",
    "    def get_configs(self): return(0)\n",
    "    \n",
    "dummyOpt = dummy_opt()\n",
    "\n",
    "model.compile(optimizer= dummyOpt,loss = dummy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 5s - loss: 2.2507\n",
      "[array([[ 0.0127599 ,  0.37172297,  0.6517402 , -0.19584408],\n",
      "       [ 0.48289487,  1.4250616 ,  0.829136  , -0.9990712 ],\n",
      "       [ 0.75429446, -0.43105736, -0.49123842, -0.916771  ],\n",
      "       [-0.5936044 , -0.28183797,  0.9929673 , -0.37372187],\n",
      "       [-2.5864205 ,  0.6306306 , -0.5808915 , -0.19506797],\n",
      "       [-0.7374694 ,  1.4341315 ,  1.0903759 , -1.2998435 ],\n",
      "       [-0.19822815,  0.9991844 , -0.36946616, -0.78892595],\n",
      "       [-0.4907518 ,  0.8508978 ,  0.0213118 ,  0.23771958],\n",
      "       [ 0.5244177 ,  0.57069975, -0.09198719,  1.6109691 ],\n",
      "       [ 1.1668501 ,  0.19878256, -0.054135  ,  0.7204712 ],\n",
      "       [ 0.22814113,  0.95615643, -0.38133034, -1.178827  ],\n",
      "       [-1.1019708 ,  0.6887924 , -0.10015344,  0.9302938 ],\n",
      "       [ 1.0542237 , -0.41386527,  1.3975052 ,  1.872338  ],\n",
      "       [ 1.0615239 ,  0.05719159,  0.16392286,  0.08765532],\n",
      "       [ 0.93025565,  1.4915359 ,  0.16463295, -1.0579904 ],\n",
      "       [ 1.4901214 ,  0.18857561, -1.3429745 ,  0.7978848 ]],\n",
      "      dtype=float32)]\n",
      "Epoch 2/10\n",
      " - 0s - loss: 2.2507\n",
      "[array([[ 0.0127599 ,  0.37172297,  0.6517402 , -0.19584408],\n",
      "       [ 0.48289487,  1.4250616 ,  0.829136  , -0.9990712 ],\n",
      "       [ 0.75429446, -0.43105736, -0.49123842, -0.916771  ],\n",
      "       [-0.5936044 , -0.28183797,  0.9929673 , -0.37372187],\n",
      "       [-2.5864205 ,  0.6306306 , -0.5808915 , -0.19506797],\n",
      "       [-0.7374694 ,  1.4341315 ,  1.0903759 , -1.2998435 ],\n",
      "       [-0.19822815,  0.9991844 , -0.36946616, -0.78892595],\n",
      "       [-0.4907518 ,  0.8508978 ,  0.0213118 ,  0.23771958],\n",
      "       [ 0.5244177 ,  0.57069975, -0.09198719,  1.6109691 ],\n",
      "       [ 1.1668501 ,  0.19878256, -0.054135  ,  0.7204712 ],\n",
      "       [ 0.22814113,  0.95615643, -0.38133034, -1.178827  ],\n",
      "       [-1.1019708 ,  0.6887924 , -0.10015344,  0.9302938 ],\n",
      "       [ 1.0542237 , -0.41386527,  1.3975052 ,  1.872338  ],\n",
      "       [ 1.0615239 ,  0.05719159,  0.16392286,  0.08765532],\n",
      "       [ 0.93025565,  1.4915359 ,  0.16463295, -1.0579904 ],\n",
      "       [ 1.4901214 ,  0.18857561, -1.3429745 ,  0.7978848 ]],\n",
      "      dtype=float32)]\n",
      "Epoch 3/10\n",
      " - 0s - loss: 2.2507\n",
      "[array([[ 0.0127599 ,  0.37172297,  0.6517402 , -0.19584408],\n",
      "       [ 0.48289487,  1.4250616 ,  0.829136  , -0.9990712 ],\n",
      "       [ 0.75429446, -0.43105736, -0.49123842, -0.916771  ],\n",
      "       [-0.5936044 , -0.28183797,  0.9929673 , -0.37372187],\n",
      "       [-2.5864205 ,  0.6306306 , -0.5808915 , -0.19506797],\n",
      "       [-0.7374694 ,  1.4341315 ,  1.0903759 , -1.2998435 ],\n",
      "       [-0.19822815,  0.9991844 , -0.36946616, -0.78892595],\n",
      "       [-0.4907518 ,  0.8508978 ,  0.0213118 ,  0.23771958],\n",
      "       [ 0.5244177 ,  0.57069975, -0.09198719,  1.6109691 ],\n",
      "       [ 1.1668501 ,  0.19878256, -0.054135  ,  0.7204712 ],\n",
      "       [ 0.22814113,  0.95615643, -0.38133034, -1.178827  ],\n",
      "       [-1.1019708 ,  0.6887924 , -0.10015344,  0.9302938 ],\n",
      "       [ 1.0542237 , -0.41386527,  1.3975052 ,  1.872338  ],\n",
      "       [ 1.0615239 ,  0.05719159,  0.16392286,  0.08765532],\n",
      "       [ 0.93025565,  1.4915359 ,  0.16463295, -1.0579904 ],\n",
      "       [ 1.4901214 ,  0.18857561, -1.3429745 ,  0.7978848 ]],\n",
      "      dtype=float32)]\n",
      "Epoch 4/10\n",
      " - 0s - loss: 2.2507\n",
      "[array([[ 0.0127599 ,  0.37172297,  0.6517402 , -0.19584408],\n",
      "       [ 0.48289487,  1.4250616 ,  0.829136  , -0.9990712 ],\n",
      "       [ 0.75429446, -0.43105736, -0.49123842, -0.916771  ],\n",
      "       [-0.5936044 , -0.28183797,  0.9929673 , -0.37372187],\n",
      "       [-2.5864205 ,  0.6306306 , -0.5808915 , -0.19506797],\n",
      "       [-0.7374694 ,  1.4341315 ,  1.0903759 , -1.2998435 ],\n",
      "       [-0.19822815,  0.9991844 , -0.36946616, -0.78892595],\n",
      "       [-0.4907518 ,  0.8508978 ,  0.0213118 ,  0.23771958],\n",
      "       [ 0.5244177 ,  0.57069975, -0.09198719,  1.6109691 ],\n",
      "       [ 1.1668501 ,  0.19878256, -0.054135  ,  0.7204712 ],\n",
      "       [ 0.22814113,  0.95615643, -0.38133034, -1.178827  ],\n",
      "       [-1.1019708 ,  0.6887924 , -0.10015344,  0.9302938 ],\n",
      "       [ 1.0542237 , -0.41386527,  1.3975052 ,  1.872338  ],\n",
      "       [ 1.0615239 ,  0.05719159,  0.16392286,  0.08765532],\n",
      "       [ 0.93025565,  1.4915359 ,  0.16463295, -1.0579904 ],\n",
      "       [ 1.4901214 ,  0.18857561, -1.3429745 ,  0.7978848 ]],\n",
      "      dtype=float32)]\n",
      "Epoch 5/10\n",
      " - 0s - loss: 2.2507\n",
      "[array([[ 0.0127599 ,  0.37172297,  0.6517402 , -0.19584408],\n",
      "       [ 0.48289487,  1.4250616 ,  0.829136  , -0.9990712 ],\n",
      "       [ 0.75429446, -0.43105736, -0.49123842, -0.916771  ],\n",
      "       [-0.5936044 , -0.28183797,  0.9929673 , -0.37372187],\n",
      "       [-2.5864205 ,  0.6306306 , -0.5808915 , -0.19506797],\n",
      "       [-0.7374694 ,  1.4341315 ,  1.0903759 , -1.2998435 ],\n",
      "       [-0.19822815,  0.9991844 , -0.36946616, -0.78892595],\n",
      "       [-0.4907518 ,  0.8508978 ,  0.0213118 ,  0.23771958],\n",
      "       [ 0.5244177 ,  0.57069975, -0.09198719,  1.6109691 ],\n",
      "       [ 1.1668501 ,  0.19878256, -0.054135  ,  0.7204712 ],\n",
      "       [ 0.22814113,  0.95615643, -0.38133034, -1.178827  ],\n",
      "       [-1.1019708 ,  0.6887924 , -0.10015344,  0.9302938 ],\n",
      "       [ 1.0542237 , -0.41386527,  1.3975052 ,  1.872338  ],\n",
      "       [ 1.0615239 ,  0.05719159,  0.16392286,  0.08765532],\n",
      "       [ 0.93025565,  1.4915359 ,  0.16463295, -1.0579904 ],\n",
      "       [ 1.4901214 ,  0.18857561, -1.3429745 ,  0.7978848 ]],\n",
      "      dtype=float32)]\n",
      "Epoch 6/10\n",
      " - 0s - loss: 2.2507\n",
      "[array([[ 0.0127599 ,  0.37172297,  0.6517402 , -0.19584408],\n",
      "       [ 0.48289487,  1.4250616 ,  0.829136  , -0.9990712 ],\n",
      "       [ 0.75429446, -0.43105736, -0.49123842, -0.916771  ],\n",
      "       [-0.5936044 , -0.28183797,  0.9929673 , -0.37372187],\n",
      "       [-2.5864205 ,  0.6306306 , -0.5808915 , -0.19506797],\n",
      "       [-0.7374694 ,  1.4341315 ,  1.0903759 , -1.2998435 ],\n",
      "       [-0.19822815,  0.9991844 , -0.36946616, -0.78892595],\n",
      "       [-0.4907518 ,  0.8508978 ,  0.0213118 ,  0.23771958],\n",
      "       [ 0.5244177 ,  0.57069975, -0.09198719,  1.6109691 ],\n",
      "       [ 1.1668501 ,  0.19878256, -0.054135  ,  0.7204712 ],\n",
      "       [ 0.22814113,  0.95615643, -0.38133034, -1.178827  ],\n",
      "       [-1.1019708 ,  0.6887924 , -0.10015344,  0.9302938 ],\n",
      "       [ 1.0542237 , -0.41386527,  1.3975052 ,  1.872338  ],\n",
      "       [ 1.0615239 ,  0.05719159,  0.16392286,  0.08765532],\n",
      "       [ 0.93025565,  1.4915359 ,  0.16463295, -1.0579904 ],\n",
      "       [ 1.4901214 ,  0.18857561, -1.3429745 ,  0.7978848 ]],\n",
      "      dtype=float32)]\n",
      "Epoch 7/10\n",
      " - 0s - loss: 2.2507\n",
      "[array([[ 0.0127599 ,  0.37172297,  0.6517402 , -0.19584408],\n",
      "       [ 0.48289487,  1.4250616 ,  0.829136  , -0.9990712 ],\n",
      "       [ 0.75429446, -0.43105736, -0.49123842, -0.916771  ],\n",
      "       [-0.5936044 , -0.28183797,  0.9929673 , -0.37372187],\n",
      "       [-2.5864205 ,  0.6306306 , -0.5808915 , -0.19506797],\n",
      "       [-0.7374694 ,  1.4341315 ,  1.0903759 , -1.2998435 ],\n",
      "       [-0.19822815,  0.9991844 , -0.36946616, -0.78892595],\n",
      "       [-0.4907518 ,  0.8508978 ,  0.0213118 ,  0.23771958],\n",
      "       [ 0.5244177 ,  0.57069975, -0.09198719,  1.6109691 ],\n",
      "       [ 1.1668501 ,  0.19878256, -0.054135  ,  0.7204712 ],\n",
      "       [ 0.22814113,  0.95615643, -0.38133034, -1.178827  ],\n",
      "       [-1.1019708 ,  0.6887924 , -0.10015344,  0.9302938 ],\n",
      "       [ 1.0542237 , -0.41386527,  1.3975052 ,  1.872338  ],\n",
      "       [ 1.0615239 ,  0.05719159,  0.16392286,  0.08765532],\n",
      "       [ 0.93025565,  1.4915359 ,  0.16463295, -1.0579904 ],\n",
      "       [ 1.4901214 ,  0.18857561, -1.3429745 ,  0.7978848 ]],\n",
      "      dtype=float32)]\n",
      "Epoch 8/10\n",
      " - 0s - loss: 2.2507\n",
      "[array([[ 0.0127599 ,  0.37172297,  0.6517402 , -0.19584408],\n",
      "       [ 0.48289487,  1.4250616 ,  0.829136  , -0.9990712 ],\n",
      "       [ 0.75429446, -0.43105736, -0.49123842, -0.916771  ],\n",
      "       [-0.5936044 , -0.28183797,  0.9929673 , -0.37372187],\n",
      "       [-2.5864205 ,  0.6306306 , -0.5808915 , -0.19506797],\n",
      "       [-0.7374694 ,  1.4341315 ,  1.0903759 , -1.2998435 ],\n",
      "       [-0.19822815,  0.9991844 , -0.36946616, -0.78892595],\n",
      "       [-0.4907518 ,  0.8508978 ,  0.0213118 ,  0.23771958],\n",
      "       [ 0.5244177 ,  0.57069975, -0.09198719,  1.6109691 ],\n",
      "       [ 1.1668501 ,  0.19878256, -0.054135  ,  0.7204712 ],\n",
      "       [ 0.22814113,  0.95615643, -0.38133034, -1.178827  ],\n",
      "       [-1.1019708 ,  0.6887924 , -0.10015344,  0.9302938 ],\n",
      "       [ 1.0542237 , -0.41386527,  1.3975052 ,  1.872338  ],\n",
      "       [ 1.0615239 ,  0.05719159,  0.16392286,  0.08765532],\n",
      "       [ 0.93025565,  1.4915359 ,  0.16463295, -1.0579904 ],\n",
      "       [ 1.4901214 ,  0.18857561, -1.3429745 ,  0.7978848 ]],\n",
      "      dtype=float32)]\n",
      "Epoch 9/10\n",
      " - 0s - loss: 2.2507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.0127599 ,  0.37172297,  0.6517402 , -0.19584408],\n",
      "       [ 0.48289487,  1.4250616 ,  0.829136  , -0.9990712 ],\n",
      "       [ 0.75429446, -0.43105736, -0.49123842, -0.916771  ],\n",
      "       [-0.5936044 , -0.28183797,  0.9929673 , -0.37372187],\n",
      "       [-2.5864205 ,  0.6306306 , -0.5808915 , -0.19506797],\n",
      "       [-0.7374694 ,  1.4341315 ,  1.0903759 , -1.2998435 ],\n",
      "       [-0.19822815,  0.9991844 , -0.36946616, -0.78892595],\n",
      "       [-0.4907518 ,  0.8508978 ,  0.0213118 ,  0.23771958],\n",
      "       [ 0.5244177 ,  0.57069975, -0.09198719,  1.6109691 ],\n",
      "       [ 1.1668501 ,  0.19878256, -0.054135  ,  0.7204712 ],\n",
      "       [ 0.22814113,  0.95615643, -0.38133034, -1.178827  ],\n",
      "       [-1.1019708 ,  0.6887924 , -0.10015344,  0.9302938 ],\n",
      "       [ 1.0542237 , -0.41386527,  1.3975052 ,  1.872338  ],\n",
      "       [ 1.0615239 ,  0.05719159,  0.16392286,  0.08765532],\n",
      "       [ 0.93025565,  1.4915359 ,  0.16463295, -1.0579904 ],\n",
      "       [ 1.4901214 ,  0.18857561, -1.3429745 ,  0.7978848 ]],\n",
      "      dtype=float32)]\n",
      "Epoch 10/10\n",
      " - 0s - loss: 2.2507\n",
      "[array([[ 0.0127599 ,  0.37172297,  0.6517402 , -0.19584408],\n",
      "       [ 0.48289487,  1.4250616 ,  0.829136  , -0.9990712 ],\n",
      "       [ 0.75429446, -0.43105736, -0.49123842, -0.916771  ],\n",
      "       [-0.5936044 , -0.28183797,  0.9929673 , -0.37372187],\n",
      "       [-2.5864205 ,  0.6306306 , -0.5808915 , -0.19506797],\n",
      "       [-0.7374694 ,  1.4341315 ,  1.0903759 , -1.2998435 ],\n",
      "       [-0.19822815,  0.9991844 , -0.36946616, -0.78892595],\n",
      "       [-0.4907518 ,  0.8508978 ,  0.0213118 ,  0.23771958],\n",
      "       [ 0.5244177 ,  0.57069975, -0.09198719,  1.6109691 ],\n",
      "       [ 1.1668501 ,  0.19878256, -0.054135  ,  0.7204712 ],\n",
      "       [ 0.22814113,  0.95615643, -0.38133034, -1.178827  ],\n",
      "       [-1.1019708 ,  0.6887924 , -0.10015344,  0.9302938 ],\n",
      "       [ 1.0542237 , -0.41386527,  1.3975052 ,  1.872338  ],\n",
      "       [ 1.0615239 ,  0.05719159,  0.16392286,  0.08765532],\n",
      "       [ 0.93025565,  1.4915359 ,  0.16463295, -1.0579904 ],\n",
      "       [ 1.4901214 ,  0.18857561, -1.3429745 ,  0.7978848 ]],\n",
      "      dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cb62eebeb8>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print_weights = LambdaCallback(on_epoch_end=lambda epoch, logs: print(model.layers[0].get_weights()))\n",
    "    \n",
    "\n",
    "history = model.fit(x = inputs_by_RF[0].reshape(1000, 1, 16), y = np.array([0]*1000), epochs = 10, verbose = 2, callbacks = [print_weights])\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.2465706 ,  1.6297497 , -0.04945281, -3.4030924 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(inputs_by_RF[0][0].reshape(1,1,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes/TODO\n",
    "\n",
    "* Implement winner-take-all - how to change values in activation tensor - trying to convert to numpy then back isn't working and can't figure out how to do it without numpy bc of cannot assign new value to indices. \n",
    "* Weights not changing (example below) - is it even possible to change weights inside the call method? That's what the original layer did... but I don't know if it actually works. If not, how do I change the weights with a custom optimization function?\n",
    "\n",
    "* Figure out how to connect many small NNs to output layer\n",
    "* Metric for measuring learning (mutual information)\n",
    "\n",
    "* Possibilities: 1) Continue pushing with unsupervised. 2) Switch to supervised - but what would be the ground truth for first layers of network? How would they backprop from the ground truth of the whole image to the small sections given to each network? \n",
    "* 1D convolutional NN - stride equal to size of RF. Filter #? - start with number of diff patterns to make it easy, can change from there.\n",
    "\n",
    "\n",
    "* Note for later - use alphabet dataset (), use samples instead of whole thing for measuring max MI of filter size to speed up learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "\n",
    "class MyLayer(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        self.kernel = self.kernel + 100\n",
    "        return K.dot(x, self.kernel)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_layer_10 (MyLayer)        (None, 1)                 1         \n",
      "=================================================================\n",
      "Total params: 1\n",
      "Trainable params: 1\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(MyLayer(input_shape = (1, 1), output_dim = 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = dummyOpt, loss = dummy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 0s - loss: 100.0390\n",
      "[array([[0.03902756]], dtype=float32)]\n",
      "Epoch 2/5\n",
      " - 0s - loss: 100.0390\n",
      "[array([[0.03902756]], dtype=float32)]\n",
      "Epoch 3/5\n",
      " - 0s - loss: 100.0390\n",
      "[array([[0.03902756]], dtype=float32)]\n",
      "Epoch 4/5\n",
      " - 0s - loss: 100.0390\n",
      "[array([[0.03902756]], dtype=float32)]\n",
      "Epoch 5/5\n",
      " - 0s - loss: 100.0390\n",
      "[array([[0.03902756]], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bffbfd8cc0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_weights = LambdaCallback(on_epoch_end=lambda epoch, logs: print(model.layers[0].get_weights()))\n",
    "model.fit(x = np.ones(10).reshape(10,1,1), y=np.zeros(10), epochs = 5, verbose = 2, callbacks = [print_weights])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODOS\n",
    "* Run again with 2*2, 3*3, 4*4, 5*5, 6*6, 7*7, 8*8 and 10%, 20%, 30%, 40%, 50% noise. Save outputs and Loss curve\n",
    "* Controls - Work on creating image sets of specific submatrix pattern size (3*3) that have varying levels of MI\n",
    "* Find Image dataset that's binarized (or binarize existing one) and do MI calculations to find max MI. To do this, sample RF sized chunks of an image until stable average MI value is reached"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
