{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN Building and Visualization Imports\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import optimizers, losses\n",
    "from keras.engine.topology import Layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Standard Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Initializations\n",
    "RF_size = 2\n",
    "stride = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pd.read_csv('binary_shapes.csv')\n",
    "inputs = inputs.drop('X1', axis = 0) # Taking out col names\n",
    "inputs = inputs.apply(pd.to_numeric)  # converting to floats\n",
    "\n",
    "inputs = inputs.values # convert to np ndarray\n",
    "inputs = inputs.reshape(955, 50, 50, 1)\n",
    "flattened_inputs = inputs.reshape(955, 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('binary_shapes_labels.csv')\n",
    "labels = labels.drop('x', axis = 0)\n",
    "labels = labels.apply(pd.to_numeric)\n",
    "labels = labels.values\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = shuffle(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_90 (Conv2D)           (None, 25, 25, 52)        260       \n",
      "_________________________________________________________________\n",
      "flatten_90 (Flatten)         (None, 32500)             0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 96)                3120096   \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 39)                3783      \n",
      "=================================================================\n",
      "Total params: 3,124,139\n",
      "Trainable params: 3,124,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape = (50,50,1), filters=52, kernel_size = RF_size, strides = stride, activation = 'relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(96, activation = 'relu'))\n",
    "model.add(Dense(39, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mod():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(input_shape = (50,50,1), filters=52, kernel_size = RF_size, strides = stride, activation = 'relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(96, activation = 'relu'))\n",
    "    model.add(Dense(39, activation = 'softmax'))\n",
    "    model.compile(optimizer = optimizers.adam(lr = 0.0005), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x = inputs, validation_split = 0.25, y = labels, batch_size = 50, epochs = 25)\n",
    "    return(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 3.4929 - acc: 0.1089 - val_loss: 3.2571 - val_acc: 0.1339\n",
      "Epoch 2/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 2.9120 - acc: 0.3115 - val_loss: 2.7515 - val_acc: 0.3096\n",
      "Epoch 3/25\n",
      "716/716 [==============================] - 1s 1000us/step - loss: 2.1676 - acc: 0.5070 - val_loss: 2.0369 - val_acc: 0.4644\n",
      "Epoch 4/25\n",
      "716/716 [==============================] - 1s 961us/step - loss: 1.4777 - acc: 0.6536 - val_loss: 1.5566 - val_acc: 0.6611\n",
      "Epoch 5/25\n",
      "716/716 [==============================] - 1s 967us/step - loss: 1.0054 - acc: 0.7933 - val_loss: 1.2074 - val_acc: 0.7238\n",
      "Epoch 6/25\n",
      "716/716 [==============================] - 1s 945us/step - loss: 0.7004 - acc: 0.8450 - val_loss: 1.1147 - val_acc: 0.6946\n",
      "Epoch 7/25\n",
      "716/716 [==============================] - 1s 979us/step - loss: 0.5648 - acc: 0.8589 - val_loss: 0.9378 - val_acc: 0.7573\n",
      "Epoch 8/25\n",
      "716/716 [==============================] - 1s 988us/step - loss: 0.4904 - acc: 0.8897 - val_loss: 0.8692 - val_acc: 0.7741\n",
      "Epoch 9/25\n",
      "716/716 [==============================] - 1s 973us/step - loss: 0.3533 - acc: 0.9134 - val_loss: 0.8649 - val_acc: 0.7741\n",
      "Epoch 10/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.3216 - acc: 0.9344 - val_loss: 0.7834 - val_acc: 0.7782\n",
      "Epoch 11/25\n",
      "716/716 [==============================] - 1s 962us/step - loss: 0.2782 - acc: 0.9413 - val_loss: 0.7405 - val_acc: 0.8159\n",
      "Epoch 12/25\n",
      "716/716 [==============================] - 1s 958us/step - loss: 0.2201 - acc: 0.9483 - val_loss: 0.7525 - val_acc: 0.8075\n",
      "Epoch 13/25\n",
      "716/716 [==============================] - 1s 917us/step - loss: 0.1856 - acc: 0.9623 - val_loss: 0.6861 - val_acc: 0.8285\n",
      "Epoch 14/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1947 - acc: 0.9581 - val_loss: 0.8877 - val_acc: 0.7866\n",
      "Epoch 15/25\n",
      "716/716 [==============================] - 1s 929us/step - loss: 0.1629 - acc: 0.9679 - val_loss: 0.7959 - val_acc: 0.7992\n",
      "Epoch 16/25\n",
      "716/716 [==============================] - 1s 978us/step - loss: 0.1190 - acc: 0.9860 - val_loss: 0.6815 - val_acc: 0.8201\n",
      "Epoch 17/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1018 - acc: 0.9874 - val_loss: 0.7247 - val_acc: 0.8159\n",
      "Epoch 18/25\n",
      "716/716 [==============================] - 1s 1000us/step - loss: 0.1074 - acc: 0.9832 - val_loss: 0.6854 - val_acc: 0.8159\n",
      "Epoch 19/25\n",
      "716/716 [==============================] - 1s 994us/step - loss: 0.0916 - acc: 0.9874 - val_loss: 0.6735 - val_acc: 0.8243\n",
      "Epoch 20/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0744 - acc: 0.9916 - val_loss: 0.6641 - val_acc: 0.8243\n",
      "Epoch 21/25\n",
      "716/716 [==============================] - 1s 975us/step - loss: 0.0638 - acc: 0.9986 - val_loss: 0.6962 - val_acc: 0.8285\n",
      "Epoch 22/25\n",
      "716/716 [==============================] - 1s 967us/step - loss: 0.0504 - acc: 0.9958 - val_loss: 0.6705 - val_acc: 0.8243\n",
      "Epoch 23/25\n",
      "716/716 [==============================] - 1s 996us/step - loss: 0.0412 - acc: 0.9972 - val_loss: 0.6395 - val_acc: 0.8326\n",
      "Epoch 24/25\n",
      "716/716 [==============================] - 1s 938us/step - loss: 0.0369 - acc: 0.9972 - val_loss: 0.6788 - val_acc: 0.8285\n",
      "Epoch 25/25\n",
      "716/716 [==============================] - 1s 985us/step - loss: 0.0322 - acc: 0.9972 - val_loss: 0.6648 - val_acc: 0.8201\n",
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 3.4714 - acc: 0.0768 - val_loss: 3.3212 - val_acc: 0.1841\n",
      "Epoch 2/25\n",
      "716/716 [==============================] - 1s 999us/step - loss: 2.9289 - acc: 0.2304 - val_loss: 2.8588 - val_acc: 0.1883\n",
      "Epoch 3/25\n",
      "716/716 [==============================] - 1s 979us/step - loss: 2.3422 - acc: 0.3883 - val_loss: 2.3836 - val_acc: 0.3891\n",
      "Epoch 4/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 1.7404 - acc: 0.5880 - val_loss: 1.8879 - val_acc: 0.5272\n",
      "Epoch 5/25\n",
      "716/716 [==============================] - 1s 988us/step - loss: 1.2246 - acc: 0.7263 - val_loss: 1.3586 - val_acc: 0.6987\n",
      "Epoch 6/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.8715 - acc: 0.7975 - val_loss: 1.1169 - val_acc: 0.7238\n",
      "Epoch 7/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.6763 - acc: 0.8534 - val_loss: 0.9862 - val_acc: 0.7657\n",
      "Epoch 8/25\n",
      "716/716 [==============================] - 1s 946us/step - loss: 0.5885 - acc: 0.8547 - val_loss: 0.9931 - val_acc: 0.7490\n",
      "Epoch 9/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.4728 - acc: 0.8869 - val_loss: 0.8333 - val_acc: 0.7699\n",
      "Epoch 10/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.4391 - acc: 0.8911 - val_loss: 0.8606 - val_acc: 0.7448\n",
      "Epoch 11/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.3584 - acc: 0.9162 - val_loss: 0.7796 - val_acc: 0.7992\n",
      "Epoch 12/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.2888 - acc: 0.9344 - val_loss: 0.7773 - val_acc: 0.7950\n",
      "Epoch 13/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.2637 - acc: 0.9358 - val_loss: 0.8211 - val_acc: 0.7824\n",
      "Epoch 14/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.2236 - acc: 0.9497 - val_loss: 0.8431 - val_acc: 0.7908\n",
      "Epoch 15/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1863 - acc: 0.9623 - val_loss: 0.7350 - val_acc: 0.8117\n",
      "Epoch 16/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1505 - acc: 0.9721 - val_loss: 0.7515 - val_acc: 0.7992\n",
      "Epoch 17/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1319 - acc: 0.9763 - val_loss: 0.7539 - val_acc: 0.7950\n",
      "Epoch 18/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1278 - acc: 0.9749 - val_loss: 0.7280 - val_acc: 0.7992\n",
      "Epoch 19/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1019 - acc: 0.9846 - val_loss: 0.8305 - val_acc: 0.7824\n",
      "Epoch 20/25\n",
      "716/716 [==============================] - 1s 979us/step - loss: 0.1063 - acc: 0.9791 - val_loss: 0.7906 - val_acc: 0.7950\n",
      "Epoch 21/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0852 - acc: 0.9888 - val_loss: 0.7734 - val_acc: 0.7992\n",
      "Epoch 22/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0673 - acc: 0.9888 - val_loss: 0.6983 - val_acc: 0.8326\n",
      "Epoch 23/25\n",
      "716/716 [==============================] - 1s 992us/step - loss: 0.0684 - acc: 0.9902 - val_loss: 0.7279 - val_acc: 0.8033\n",
      "Epoch 24/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0565 - acc: 0.9916 - val_loss: 0.6727 - val_acc: 0.8159\n",
      "Epoch 25/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0455 - acc: 0.9986 - val_loss: 0.7709 - val_acc: 0.8033\n",
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 3.4794 - acc: 0.1117 - val_loss: 3.1753 - val_acc: 0.2218\n",
      "Epoch 2/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 2.7921 - acc: 0.2975 - val_loss: 2.5706 - val_acc: 0.3431\n",
      "Epoch 3/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 2.0151 - acc: 0.5126 - val_loss: 1.9010 - val_acc: 0.5230\n",
      "Epoch 4/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 1.3081 - acc: 0.7137 - val_loss: 1.4908 - val_acc: 0.6109\n",
      "Epoch 5/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.9305 - acc: 0.7961 - val_loss: 1.2274 - val_acc: 0.6695\n",
      "Epoch 6/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.7254 - acc: 0.8338 - val_loss: 1.1960 - val_acc: 0.7071\n",
      "Epoch 7/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.6808 - acc: 0.8226 - val_loss: 1.1530 - val_acc: 0.6946\n",
      "Epoch 8/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.5118 - acc: 0.8645 - val_loss: 0.9905 - val_acc: 0.7824\n",
      "Epoch 9/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.4127 - acc: 0.8966 - val_loss: 0.8550 - val_acc: 0.7573\n",
      "Epoch 10/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.3555 - acc: 0.9190 - val_loss: 0.7737 - val_acc: 0.7908\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716/716 [==============================] - 1s 1ms/step - loss: 0.2940 - acc: 0.9316 - val_loss: 0.7663 - val_acc: 0.7782\n",
      "Epoch 12/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.2566 - acc: 0.9344 - val_loss: 0.7671 - val_acc: 0.7866\n",
      "Epoch 13/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1981 - acc: 0.9651 - val_loss: 0.8072 - val_acc: 0.8033\n",
      "Epoch 14/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1861 - acc: 0.9623 - val_loss: 0.7049 - val_acc: 0.8159\n",
      "Epoch 15/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1455 - acc: 0.9693 - val_loss: 0.6941 - val_acc: 0.8326\n",
      "Epoch 16/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1357 - acc: 0.9749 - val_loss: 0.6746 - val_acc: 0.8159\n",
      "Epoch 17/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1349 - acc: 0.9735 - val_loss: 0.7398 - val_acc: 0.7950\n",
      "Epoch 18/25\n",
      "716/716 [==============================] - 1s 991us/step - loss: 0.1027 - acc: 0.9860 - val_loss: 0.6865 - val_acc: 0.8201\n",
      "Epoch 19/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1471 - acc: 0.9637 - val_loss: 1.0416 - val_acc: 0.8075\n",
      "Epoch 20/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.2276 - acc: 0.9483 - val_loss: 0.8346 - val_acc: 0.7699\n",
      "Epoch 21/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.2731 - acc: 0.9427 - val_loss: 0.9388 - val_acc: 0.7782\n",
      "Epoch 22/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1542 - acc: 0.9637 - val_loss: 0.9910 - val_acc: 0.8201\n",
      "Epoch 23/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0971 - acc: 0.9874 - val_loss: 0.7317 - val_acc: 0.8243\n",
      "Epoch 24/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0560 - acc: 0.9958 - val_loss: 0.6749 - val_acc: 0.8368\n",
      "Epoch 25/25\n",
      "716/716 [==============================] - 1s 998us/step - loss: 0.0436 - acc: 0.9972 - val_loss: 0.8029 - val_acc: 0.8075\n",
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 3.5574 - acc: 0.0936 - val_loss: 3.3956 - val_acc: 0.1464\n",
      "Epoch 2/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 3.1054 - acc: 0.2277 - val_loss: 2.9253 - val_acc: 0.3640\n",
      "Epoch 3/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 2.4200 - acc: 0.4665 - val_loss: 2.3869 - val_acc: 0.4477\n",
      "Epoch 4/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 1.7294 - acc: 0.6369 - val_loss: 1.6879 - val_acc: 0.6276\n",
      "Epoch 5/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 1.1660 - acc: 0.7458 - val_loss: 1.4406 - val_acc: 0.6360\n",
      "Epoch 6/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.8885 - acc: 0.8017 - val_loss: 1.1308 - val_acc: 0.7322\n",
      "Epoch 7/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.6969 - acc: 0.8436 - val_loss: 0.9458 - val_acc: 0.7448\n",
      "Epoch 8/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.5300 - acc: 0.8869 - val_loss: 0.9230 - val_acc: 0.7531\n",
      "Epoch 9/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.4579 - acc: 0.8966 - val_loss: 0.8278 - val_acc: 0.7657\n",
      "Epoch 10/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.4007 - acc: 0.9050 - val_loss: 0.7831 - val_acc: 0.7992\n",
      "Epoch 11/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.3400 - acc: 0.9190 - val_loss: 0.8519 - val_acc: 0.7824\n",
      "Epoch 12/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.2670 - acc: 0.9441 - val_loss: 0.8029 - val_acc: 0.7741\n",
      "Epoch 13/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.2714 - acc: 0.9330 - val_loss: 0.7578 - val_acc: 0.7824\n",
      "Epoch 14/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1970 - acc: 0.9595 - val_loss: 0.7779 - val_acc: 0.7866\n",
      "Epoch 15/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1877 - acc: 0.9651 - val_loss: 0.7126 - val_acc: 0.8117\n",
      "Epoch 16/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1673 - acc: 0.9637 - val_loss: 0.7786 - val_acc: 0.7950\n",
      "Epoch 17/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1464 - acc: 0.9693 - val_loss: 0.7145 - val_acc: 0.7908\n",
      "Epoch 18/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1197 - acc: 0.9791 - val_loss: 0.8008 - val_acc: 0.7866\n",
      "Epoch 19/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1230 - acc: 0.9804 - val_loss: 0.7240 - val_acc: 0.8159\n",
      "Epoch 20/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0867 - acc: 0.9902 - val_loss: 0.7210 - val_acc: 0.8117\n",
      "Epoch 21/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0708 - acc: 0.9916 - val_loss: 0.6924 - val_acc: 0.8075\n",
      "Epoch 22/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0692 - acc: 0.9916 - val_loss: 0.6579 - val_acc: 0.8410\n",
      "Epoch 23/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0594 - acc: 0.9958 - val_loss: 0.7576 - val_acc: 0.7992\n",
      "Epoch 24/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1103 - acc: 0.9791 - val_loss: 1.0180 - val_acc: 0.7824\n",
      "Epoch 25/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0702 - acc: 0.9874 - val_loss: 0.7749 - val_acc: 0.7573\n",
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/25\n",
      "716/716 [==============================] - 5s 8ms/step - loss: 3.4736 - acc: 0.1201 - val_loss: 3.2566 - val_acc: 0.1841\n",
      "Epoch 2/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 2.8569 - acc: 0.2807 - val_loss: 2.5791 - val_acc: 0.3975\n",
      "Epoch 3/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 2.0457 - acc: 0.4846 - val_loss: 1.8433 - val_acc: 0.5900\n",
      "Epoch 4/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 1.3121 - acc: 0.7095 - val_loss: 1.3386 - val_acc: 0.6862\n",
      "Epoch 5/25\n",
      "716/716 [==============================] - 1s 958us/step - loss: 0.9221 - acc: 0.7765 - val_loss: 1.1206 - val_acc: 0.7113\n",
      "Epoch 6/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.6813 - acc: 0.8352 - val_loss: 1.0545 - val_acc: 0.7113\n",
      "Epoch 7/25\n",
      "716/716 [==============================] - 1s 999us/step - loss: 0.5072 - acc: 0.8841 - val_loss: 0.9752 - val_acc: 0.7322\n",
      "Epoch 8/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.4329 - acc: 0.8897 - val_loss: 0.8225 - val_acc: 0.7908\n",
      "Epoch 9/25\n",
      "716/716 [==============================] - 1s 995us/step - loss: 0.3453 - acc: 0.9246 - val_loss: 0.8331 - val_acc: 0.7782\n",
      "Epoch 10/25\n",
      "716/716 [==============================] - 1s 983us/step - loss: 0.2779 - acc: 0.9539 - val_loss: 0.8050 - val_acc: 0.7657\n",
      "Epoch 11/25\n",
      "716/716 [==============================] - 1s 960us/step - loss: 0.2368 - acc: 0.9427 - val_loss: 0.8386 - val_acc: 0.7824\n",
      "Epoch 12/25\n",
      "716/716 [==============================] - 1s 986us/step - loss: 0.2214 - acc: 0.9469 - val_loss: 0.8201 - val_acc: 0.7490\n",
      "Epoch 13/25\n",
      "716/716 [==============================] - 1s 998us/step - loss: 0.2469 - acc: 0.9385 - val_loss: 0.8987 - val_acc: 0.7741\n",
      "Epoch 14/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1937 - acc: 0.9567 - val_loss: 0.8244 - val_acc: 0.7531\n",
      "Epoch 15/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1510 - acc: 0.9651 - val_loss: 0.8152 - val_acc: 0.7782\n",
      "Epoch 16/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1156 - acc: 0.9791 - val_loss: 0.7920 - val_acc: 0.7782\n",
      "Epoch 17/25\n",
      "716/716 [==============================] - 1s 983us/step - loss: 0.1052 - acc: 0.9846 - val_loss: 0.6929 - val_acc: 0.8075\n",
      "Epoch 18/25\n",
      "716/716 [==============================] - 1s 958us/step - loss: 0.1106 - acc: 0.9749 - val_loss: 0.7769 - val_acc: 0.7992\n",
      "Epoch 19/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1175 - acc: 0.9707 - val_loss: 0.8460 - val_acc: 0.7992\n",
      "Epoch 20/25\n",
      "716/716 [==============================] - 1s 960us/step - loss: 0.0786 - acc: 0.9874 - val_loss: 0.8693 - val_acc: 0.7950\n",
      "Epoch 21/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0759 - acc: 0.9860 - val_loss: 0.6779 - val_acc: 0.8159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0436 - acc: 0.9972 - val_loss: 0.7396 - val_acc: 0.7950\n",
      "Epoch 23/25\n",
      "716/716 [==============================] - 1s 945us/step - loss: 0.0368 - acc: 0.9958 - val_loss: 0.8101 - val_acc: 0.7992\n",
      "Epoch 24/25\n",
      "716/716 [==============================] - 1s 973us/step - loss: 0.0372 - acc: 0.9972 - val_loss: 0.8388 - val_acc: 0.7992\n",
      "Epoch 25/25\n",
      "716/716 [==============================] - 1s 937us/step - loss: 0.0263 - acc: 1.0000 - val_loss: 0.6963 - val_acc: 0.8285\n",
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 3.4776 - acc: 0.1047 - val_loss: 3.2874 - val_acc: 0.1339\n",
      "Epoch 2/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 2.9042 - acc: 0.2528 - val_loss: 2.7161 - val_acc: 0.4059\n",
      "Epoch 3/25\n",
      "716/716 [==============================] - 1s 937us/step - loss: 2.2089 - acc: 0.5056 - val_loss: 2.1685 - val_acc: 0.4603\n",
      "Epoch 4/25\n",
      "716/716 [==============================] - 1s 912us/step - loss: 1.5551 - acc: 0.6285 - val_loss: 1.5639 - val_acc: 0.6276\n",
      "Epoch 5/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 1.0565 - acc: 0.7556 - val_loss: 1.2375 - val_acc: 0.6987\n",
      "Epoch 6/25\n",
      "716/716 [==============================] - 1s 930us/step - loss: 0.7829 - acc: 0.8366 - val_loss: 0.9758 - val_acc: 0.7615\n",
      "Epoch 7/25\n",
      "716/716 [==============================] - 1s 880us/step - loss: 0.6083 - acc: 0.8701 - val_loss: 0.9747 - val_acc: 0.7448\n",
      "Epoch 8/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.4816 - acc: 0.8869 - val_loss: 0.8435 - val_acc: 0.7866\n",
      "Epoch 9/25\n",
      "716/716 [==============================] - 1s 999us/step - loss: 0.4161 - acc: 0.8980 - val_loss: 0.9162 - val_acc: 0.7573\n",
      "Epoch 10/25\n",
      "716/716 [==============================] - 1s 994us/step - loss: 0.3568 - acc: 0.9204 - val_loss: 0.7795 - val_acc: 0.7908\n",
      "Epoch 11/25\n",
      "716/716 [==============================] - 1s 999us/step - loss: 0.3069 - acc: 0.9302 - val_loss: 0.7495 - val_acc: 0.8159\n",
      "Epoch 12/25\n",
      "716/716 [==============================] - 1s 991us/step - loss: 0.2740 - acc: 0.9427 - val_loss: 0.7163 - val_acc: 0.7908\n",
      "Epoch 13/25\n",
      "716/716 [==============================] - 1s 981us/step - loss: 0.2295 - acc: 0.9455 - val_loss: 0.7592 - val_acc: 0.7782\n",
      "Epoch 14/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1960 - acc: 0.9553 - val_loss: 0.7124 - val_acc: 0.8075\n",
      "Epoch 15/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1530 - acc: 0.9777 - val_loss: 0.7089 - val_acc: 0.8075\n",
      "Epoch 16/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1534 - acc: 0.9707 - val_loss: 0.7459 - val_acc: 0.7741\n",
      "Epoch 17/25\n",
      "716/716 [==============================] - 1s 984us/step - loss: 0.1357 - acc: 0.9707 - val_loss: 0.6559 - val_acc: 0.8285\n",
      "Epoch 18/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1130 - acc: 0.9832 - val_loss: 0.7258 - val_acc: 0.7992\n",
      "Epoch 19/25\n",
      "716/716 [==============================] - 1s 938us/step - loss: 0.0902 - acc: 0.9916 - val_loss: 0.7372 - val_acc: 0.7950\n",
      "Epoch 20/25\n",
      "716/716 [==============================] - 1s 914us/step - loss: 0.0680 - acc: 0.9930 - val_loss: 0.6817 - val_acc: 0.8159\n",
      "Epoch 21/25\n",
      "716/716 [==============================] - 1s 932us/step - loss: 0.0584 - acc: 0.9972 - val_loss: 0.6613 - val_acc: 0.8159\n",
      "Epoch 22/25\n",
      "716/716 [==============================] - 1s 984us/step - loss: 0.0534 - acc: 0.9972 - val_loss: 0.6934 - val_acc: 0.8201\n",
      "Epoch 23/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0485 - acc: 0.9958 - val_loss: 0.7048 - val_acc: 0.8117\n",
      "Epoch 24/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0782 - acc: 0.9860 - val_loss: 0.7330 - val_acc: 0.8117\n",
      "Epoch 25/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0853 - acc: 0.9818 - val_loss: 0.7243 - val_acc: 0.8075\n",
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 3.4845 - acc: 0.1061 - val_loss: 3.2734 - val_acc: 0.1925\n",
      "Epoch 2/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 2.8880 - acc: 0.2528 - val_loss: 2.6422 - val_acc: 0.3431\n",
      "Epoch 3/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 2.0490 - acc: 0.5098 - val_loss: 1.9499 - val_acc: 0.4854\n",
      "Epoch 4/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 1.3880 - acc: 0.6592 - val_loss: 1.4759 - val_acc: 0.6109\n",
      "Epoch 5/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.9446 - acc: 0.7835 - val_loss: 1.1154 - val_acc: 0.6904\n",
      "Epoch 6/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.6624 - acc: 0.8408 - val_loss: 0.9882 - val_acc: 0.7490\n",
      "Epoch 7/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.5414 - acc: 0.8785 - val_loss: 0.8699 - val_acc: 0.7657\n",
      "Epoch 8/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.4420 - acc: 0.8939 - val_loss: 0.8403 - val_acc: 0.7992\n",
      "Epoch 9/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.3828 - acc: 0.9092 - val_loss: 0.9434 - val_acc: 0.7741\n",
      "Epoch 10/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.3423 - acc: 0.9162 - val_loss: 0.9324 - val_acc: 0.7490\n",
      "Epoch 11/25\n",
      "716/716 [==============================] - 1s 907us/step - loss: 0.2814 - acc: 0.9330 - val_loss: 0.8169 - val_acc: 0.7908\n",
      "Epoch 12/25\n",
      "716/716 [==============================] - 1s 932us/step - loss: 0.2248 - acc: 0.9483 - val_loss: 0.8600 - val_acc: 0.7992\n",
      "Epoch 13/25\n",
      "716/716 [==============================] - 1s 897us/step - loss: 0.1970 - acc: 0.9511 - val_loss: 0.6863 - val_acc: 0.8159\n",
      "Epoch 14/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1488 - acc: 0.9749 - val_loss: 0.7436 - val_acc: 0.7950\n",
      "Epoch 15/25\n",
      "716/716 [==============================] - 1s 985us/step - loss: 0.1351 - acc: 0.9804 - val_loss: 0.6834 - val_acc: 0.8201\n",
      "Epoch 16/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1018 - acc: 0.9888 - val_loss: 0.7013 - val_acc: 0.8243\n",
      "Epoch 17/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0997 - acc: 0.9902 - val_loss: 0.6219 - val_acc: 0.8326\n",
      "Epoch 18/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0713 - acc: 0.9972 - val_loss: 0.6139 - val_acc: 0.8326\n",
      "Epoch 19/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0602 - acc: 0.9958 - val_loss: 0.6346 - val_acc: 0.8243\n",
      "Epoch 20/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0806 - acc: 0.9804 - val_loss: 0.6575 - val_acc: 0.8326\n",
      "Epoch 21/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0757 - acc: 0.9902 - val_loss: 0.6443 - val_acc: 0.8243\n",
      "Epoch 22/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0536 - acc: 0.9958 - val_loss: 0.7133 - val_acc: 0.8243\n",
      "Epoch 23/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1050 - acc: 0.9791 - val_loss: 0.7654 - val_acc: 0.8159\n",
      "Epoch 24/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0531 - acc: 0.9972 - val_loss: 0.7430 - val_acc: 0.8201\n",
      "Epoch 25/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0355 - acc: 0.9958 - val_loss: 0.7439 - val_acc: 0.8410\n",
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 3.4680 - acc: 0.0992 - val_loss: 3.1840 - val_acc: 0.1757\n",
      "Epoch 2/25\n",
      "716/716 [==============================] - 1s 990us/step - loss: 2.7614 - acc: 0.3156 - val_loss: 2.5125 - val_acc: 0.3598\n",
      "Epoch 3/25\n",
      "716/716 [==============================] - 1s 941us/step - loss: 1.9239 - acc: 0.5419 - val_loss: 1.8417 - val_acc: 0.5941\n",
      "Epoch 4/25\n",
      "716/716 [==============================] - 1s 999us/step - loss: 1.2515 - acc: 0.7109 - val_loss: 1.3451 - val_acc: 0.7029\n",
      "Epoch 5/25\n",
      "716/716 [==============================] - 1s 961us/step - loss: 0.8956 - acc: 0.7891 - val_loss: 1.1188 - val_acc: 0.7280\n",
      "Epoch 6/25\n",
      "716/716 [==============================] - 1s 970us/step - loss: 0.6513 - acc: 0.8436 - val_loss: 1.0357 - val_acc: 0.7197\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716/716 [==============================] - 1s 1ms/step - loss: 0.5177 - acc: 0.8743 - val_loss: 1.0356 - val_acc: 0.7155\n",
      "Epoch 8/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.4197 - acc: 0.9134 - val_loss: 0.8060 - val_acc: 0.8033\n",
      "Epoch 9/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.3431 - acc: 0.9120 - val_loss: 0.8803 - val_acc: 0.7573\n",
      "Epoch 10/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.3485 - acc: 0.9162 - val_loss: 0.8530 - val_acc: 0.7573\n",
      "Epoch 11/25\n",
      "716/716 [==============================] - 1s 997us/step - loss: 0.2648 - acc: 0.9455 - val_loss: 0.8095 - val_acc: 0.7741\n",
      "Epoch 12/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.2075 - acc: 0.9623 - val_loss: 0.8215 - val_acc: 0.7866\n",
      "Epoch 13/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1888 - acc: 0.9623 - val_loss: 0.7199 - val_acc: 0.7950\n",
      "Epoch 14/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1764 - acc: 0.9665 - val_loss: 0.7679 - val_acc: 0.8033\n",
      "Epoch 15/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1222 - acc: 0.9832 - val_loss: 0.7113 - val_acc: 0.8159\n",
      "Epoch 16/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0973 - acc: 0.9888 - val_loss: 0.6975 - val_acc: 0.8201\n",
      "Epoch 17/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0810 - acc: 0.9958 - val_loss: 0.7117 - val_acc: 0.8075\n",
      "Epoch 18/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0732 - acc: 0.9916 - val_loss: 0.7180 - val_acc: 0.8285\n",
      "Epoch 19/25\n",
      "716/716 [==============================] - 1s 976us/step - loss: 0.0639 - acc: 0.9944 - val_loss: 0.7304 - val_acc: 0.8075\n",
      "Epoch 20/25\n",
      "716/716 [==============================] - 1s 950us/step - loss: 0.0569 - acc: 0.9972 - val_loss: 0.6955 - val_acc: 0.8201\n",
      "Epoch 21/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0596 - acc: 0.9930 - val_loss: 0.6939 - val_acc: 0.8201\n",
      "Epoch 22/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0662 - acc: 0.9888 - val_loss: 0.7890 - val_acc: 0.7908\n",
      "Epoch 23/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1186 - acc: 0.9665 - val_loss: 0.7932 - val_acc: 0.8075\n",
      "Epoch 24/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0638 - acc: 0.9916 - val_loss: 0.6705 - val_acc: 0.8201\n",
      "Epoch 25/25\n",
      "716/716 [==============================] - 1s 989us/step - loss: 0.0412 - acc: 0.9930 - val_loss: 0.6922 - val_acc: 0.8243\n",
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 3.4767 - acc: 0.1187 - val_loss: 3.2853 - val_acc: 0.2008\n",
      "Epoch 2/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 2.8792 - acc: 0.2793 - val_loss: 2.7243 - val_acc: 0.3347\n",
      "Epoch 3/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 2.1717 - acc: 0.4860 - val_loss: 2.1226 - val_acc: 0.4812\n",
      "Epoch 4/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 1.4441 - acc: 0.6885 - val_loss: 1.5593 - val_acc: 0.5900\n",
      "Epoch 5/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.9946 - acc: 0.7486 - val_loss: 1.2797 - val_acc: 0.6862\n",
      "Epoch 6/25\n",
      "716/716 [==============================] - 1s 998us/step - loss: 0.7289 - acc: 0.8240 - val_loss: 0.9779 - val_acc: 0.7615\n",
      "Epoch 7/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.5870 - acc: 0.8589 - val_loss: 1.1342 - val_acc: 0.6946\n",
      "Epoch 8/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.5153 - acc: 0.8603 - val_loss: 0.9676 - val_acc: 0.7364\n",
      "Epoch 9/25\n",
      "716/716 [==============================] - 1s 987us/step - loss: 0.3849 - acc: 0.9106 - val_loss: 0.9496 - val_acc: 0.7406\n",
      "Epoch 10/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.3144 - acc: 0.9232 - val_loss: 0.7675 - val_acc: 0.7782\n",
      "Epoch 11/25\n",
      "716/716 [==============================] - 1s 996us/step - loss: 0.2778 - acc: 0.9358 - val_loss: 0.7881 - val_acc: 0.7866\n",
      "Epoch 12/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.2251 - acc: 0.9455 - val_loss: 0.7684 - val_acc: 0.7824\n",
      "Epoch 13/25\n",
      "716/716 [==============================] - 1s 991us/step - loss: 0.1801 - acc: 0.9651 - val_loss: 0.7604 - val_acc: 0.7866\n",
      "Epoch 14/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1773 - acc: 0.9581 - val_loss: 0.8440 - val_acc: 0.7908\n",
      "Epoch 15/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1617 - acc: 0.9581 - val_loss: 0.7258 - val_acc: 0.8117\n",
      "Epoch 16/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1365 - acc: 0.9693 - val_loss: 0.6677 - val_acc: 0.8117\n",
      "Epoch 17/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0935 - acc: 0.9888 - val_loss: 0.7035 - val_acc: 0.8159\n",
      "Epoch 18/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0750 - acc: 0.9902 - val_loss: 0.6476 - val_acc: 0.8075\n",
      "Epoch 19/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0691 - acc: 0.9902 - val_loss: 0.7245 - val_acc: 0.8033\n",
      "Epoch 20/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0711 - acc: 0.9888 - val_loss: 0.7422 - val_acc: 0.8033\n",
      "Epoch 21/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0929 - acc: 0.9832 - val_loss: 0.7572 - val_acc: 0.8075\n",
      "Epoch 22/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0775 - acc: 0.9860 - val_loss: 0.6554 - val_acc: 0.8243\n",
      "Epoch 23/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0428 - acc: 0.9986 - val_loss: 0.6184 - val_acc: 0.7950\n",
      "Epoch 24/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0325 - acc: 0.9986 - val_loss: 0.6478 - val_acc: 0.8201\n",
      "Epoch 25/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0268 - acc: 0.9986 - val_loss: 0.6843 - val_acc: 0.8117\n",
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/25\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 3.4558 - acc: 0.0796 - val_loss: 3.2810 - val_acc: 0.1423\n",
      "Epoch 2/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 2.8812 - acc: 0.2598 - val_loss: 2.6876 - val_acc: 0.3598\n",
      "Epoch 3/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 2.1411 - acc: 0.4930 - val_loss: 2.2188 - val_acc: 0.4895\n",
      "Epoch 4/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 1.4883 - acc: 0.6355 - val_loss: 1.7871 - val_acc: 0.5481\n",
      "Epoch 5/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 1.0498 - acc: 0.7486 - val_loss: 1.3024 - val_acc: 0.6444\n",
      "Epoch 6/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.7486 - acc: 0.8268 - val_loss: 1.0997 - val_acc: 0.7155\n",
      "Epoch 7/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.6137 - acc: 0.8534 - val_loss: 1.0066 - val_acc: 0.7406\n",
      "Epoch 8/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.4826 - acc: 0.8785 - val_loss: 0.9078 - val_acc: 0.7490\n",
      "Epoch 9/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.4122 - acc: 0.9106 - val_loss: 0.8355 - val_acc: 0.7782\n",
      "Epoch 10/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.3204 - acc: 0.9274 - val_loss: 0.8558 - val_acc: 0.7741\n",
      "Epoch 11/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.2725 - acc: 0.9483 - val_loss: 0.8152 - val_acc: 0.7699\n",
      "Epoch 12/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.2363 - acc: 0.9483 - val_loss: 0.7806 - val_acc: 0.7866\n",
      "Epoch 13/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.2071 - acc: 0.9511 - val_loss: 0.8747 - val_acc: 0.7448\n",
      "Epoch 14/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1763 - acc: 0.9651 - val_loss: 0.7592 - val_acc: 0.7950\n",
      "Epoch 15/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1285 - acc: 0.9777 - val_loss: 0.7616 - val_acc: 0.7992\n",
      "Epoch 16/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1237 - acc: 0.9791 - val_loss: 0.8308 - val_acc: 0.8117\n",
      "Epoch 17/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.1286 - acc: 0.9693 - val_loss: 0.7718 - val_acc: 0.8117\n",
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0940 - acc: 0.9846 - val_loss: 0.7494 - val_acc: 0.8117\n",
      "Epoch 19/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0742 - acc: 0.9902 - val_loss: 0.7363 - val_acc: 0.8285\n",
      "Epoch 20/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0731 - acc: 0.9874 - val_loss: 0.7249 - val_acc: 0.8117\n",
      "Epoch 21/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0533 - acc: 0.9958 - val_loss: 0.6936 - val_acc: 0.8368\n",
      "Epoch 22/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0487 - acc: 0.9986 - val_loss: 0.7426 - val_acc: 0.8368\n",
      "Epoch 23/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0541 - acc: 0.9916 - val_loss: 0.8095 - val_acc: 0.8201\n",
      "Epoch 24/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0404 - acc: 0.9972 - val_loss: 0.8002 - val_acc: 0.8285\n",
      "Epoch 25/25\n",
      "716/716 [==============================] - 1s 1ms/step - loss: 0.0427 - acc: 0.9958 - val_loss: 0.8557 - val_acc: 0.8285\n",
      "acc15 = 0.6887029339578861 \n",
      " acc100 = 0.8129707110975577 \n",
      " loss15 = 1.2408249041026604 \n",
      " loss100 = 0.7410133349346817\n"
     ]
    }
   ],
   "source": [
    "val_acc5 = np.zeros(10)\n",
    "val_acc25 = np.zeros(10)\n",
    "val_loss5 = np.zeros(10)\n",
    "val_loss25 = np.zeros(10)\n",
    "for i in range(10):\n",
    "        results = run_mod()\n",
    "        val_acc5[i] = results.history['val_acc'][4]\n",
    "        val_acc25[i] = results.history['val_acc'][24]\n",
    "        val_loss5[i] = results.history['val_loss'][4]\n",
    "        val_loss25[i] = results.history['val_loss'][24]\n",
    "        \n",
    "print(\"acc15 = \" + str(np.mean(val_acc5)), \"\\n\",\n",
    "      \"acc100 = \" + str(np.mean(val_acc25)), \"\\n\",\n",
    "      \"loss15 = \" + str(np.mean(val_loss5)), \"\\n\",\n",
    "     \"loss100 = \" + str(np.mean(val_loss25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27698aba710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27698b292e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "* make sure image set MI caluclations for binary shapes datasets are right its doing it for all 955 with 2*2 clusters \n",
    "* for 8x8 the filter you have to learn is more complex but eventually its more efficient, maybe thats why loss is less for 2x2 at 15 epochs\n",
    "* Also more paramters to tune with larger RF size, but same LR and same # of epochs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 716 samples, validate on 239 samples\n",
      "Epoch 1/100\n",
      "716/716 [==============================] - 5s 7ms/step - loss: 3.3994 - acc: 0.1536 - val_loss: 3.0667 - val_acc: 0.2720\n",
      "Epoch 2/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 2.5525 - acc: 0.4302 - val_loss: 2.6166 - val_acc: 0.4059\n",
      "Epoch 3/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 1.9698 - acc: 0.5293 - val_loss: 2.2005 - val_acc: 0.4561\n",
      "Epoch 4/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 1.4676 - acc: 0.6606 - val_loss: 1.7521 - val_acc: 0.5523\n",
      "Epoch 5/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 1.0326 - acc: 0.7835 - val_loss: 1.4461 - val_acc: 0.6653\n",
      "Epoch 6/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.7769 - acc: 0.8408 - val_loss: 1.2441 - val_acc: 0.6778\n",
      "Epoch 7/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.6285 - acc: 0.8659 - val_loss: 1.1151 - val_acc: 0.7113\n",
      "Epoch 8/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.5125 - acc: 0.8771 - val_loss: 0.9741 - val_acc: 0.7448\n",
      "Epoch 9/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.4346 - acc: 0.8869 - val_loss: 0.9739 - val_acc: 0.7615\n",
      "Epoch 10/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.3977 - acc: 0.9008 - val_loss: 0.9163 - val_acc: 0.7197\n",
      "Epoch 11/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.2876 - acc: 0.9441 - val_loss: 0.7789 - val_acc: 0.7741\n",
      "Epoch 12/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.2376 - acc: 0.9511 - val_loss: 0.8409 - val_acc: 0.7699\n",
      "Epoch 13/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.2042 - acc: 0.9595 - val_loss: 0.8611 - val_acc: 0.7657\n",
      "Epoch 14/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.1637 - acc: 0.9749 - val_loss: 0.7522 - val_acc: 0.8159\n",
      "Epoch 15/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.1200 - acc: 0.9860 - val_loss: 0.7149 - val_acc: 0.7992\n",
      "Epoch 16/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0939 - acc: 0.9874 - val_loss: 0.6700 - val_acc: 0.8159\n",
      "Epoch 17/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0877 - acc: 0.9930 - val_loss: 0.6791 - val_acc: 0.8159\n",
      "Epoch 18/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0697 - acc: 0.9972 - val_loss: 0.7209 - val_acc: 0.8159\n",
      "Epoch 19/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0666 - acc: 0.9930 - val_loss: 0.7095 - val_acc: 0.8075\n",
      "Epoch 20/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0519 - acc: 0.9986 - val_loss: 0.6990 - val_acc: 0.8117\n",
      "Epoch 21/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0438 - acc: 1.0000 - val_loss: 0.6558 - val_acc: 0.8494\n",
      "Epoch 22/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0392 - acc: 0.9986 - val_loss: 0.6333 - val_acc: 0.8326\n",
      "Epoch 23/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0394 - acc: 1.0000 - val_loss: 0.6656 - val_acc: 0.8201\n",
      "Epoch 24/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0507 - acc: 0.9916 - val_loss: 0.7094 - val_acc: 0.8075\n",
      "Epoch 25/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0390 - acc: 0.9986 - val_loss: 0.6745 - val_acc: 0.8368\n",
      "Epoch 26/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0437 - acc: 0.9902 - val_loss: 0.6573 - val_acc: 0.8159\n",
      "Epoch 27/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0446 - acc: 0.9916 - val_loss: 0.6963 - val_acc: 0.8033\n",
      "Epoch 28/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0281 - acc: 0.9958 - val_loss: 0.6506 - val_acc: 0.8452\n",
      "Epoch 29/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.6472 - val_acc: 0.8368\n",
      "Epoch 30/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0193 - acc: 0.9986 - val_loss: 0.6841 - val_acc: 0.8326\n",
      "Epoch 31/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0159 - acc: 1.0000 - val_loss: 0.6442 - val_acc: 0.8452\n",
      "Epoch 32/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.6562 - val_acc: 0.8410\n",
      "Epoch 33/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.6527 - val_acc: 0.8452\n",
      "Epoch 34/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.6430 - val_acc: 0.8452\n",
      "Epoch 35/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.6442 - val_acc: 0.8368\n",
      "Epoch 36/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.6594 - val_acc: 0.8410\n",
      "Epoch 37/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.6619 - val_acc: 0.8452\n",
      "Epoch 38/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.6504 - val_acc: 0.8494\n",
      "Epoch 39/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.6601 - val_acc: 0.8368\n",
      "Epoch 40/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.6541 - val_acc: 0.8452\n",
      "Epoch 41/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.6662 - val_acc: 0.8410\n",
      "Epoch 42/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.6454 - val_acc: 0.8536\n",
      "Epoch 43/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.6610 - val_acc: 0.8410\n",
      "Epoch 44/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.6596 - val_acc: 0.8494\n",
      "Epoch 45/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.6685 - val_acc: 0.8410\n",
      "Epoch 46/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.6578 - val_acc: 0.8410\n",
      "Epoch 47/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.6571 - val_acc: 0.8452\n",
      "Epoch 48/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.6583 - val_acc: 0.8536\n",
      "Epoch 49/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.6626 - val_acc: 0.8452\n",
      "Epoch 50/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.6600 - val_acc: 0.8494\n",
      "Epoch 51/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.6682 - val_acc: 0.8410\n",
      "Epoch 52/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.6674 - val_acc: 0.8452\n",
      "Epoch 53/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.6665 - val_acc: 0.8494\n",
      "Epoch 54/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.6726 - val_acc: 0.8452\n",
      "Epoch 55/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.6715 - val_acc: 0.8452\n",
      "Epoch 56/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.6713 - val_acc: 0.8410\n",
      "Epoch 57/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.6805 - val_acc: 0.8452\n",
      "Epoch 58/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.6770 - val_acc: 0.8536\n",
      "Epoch 59/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.6738 - val_acc: 0.8494\n",
      "Epoch 60/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.6806 - val_acc: 0.8452\n",
      "Epoch 61/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6782 - val_acc: 0.8410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6816 - val_acc: 0.8494\n",
      "Epoch 63/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6897 - val_acc: 0.8452\n",
      "Epoch 64/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6787 - val_acc: 0.8452\n",
      "Epoch 65/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.7076 - val_acc: 0.8452\n",
      "Epoch 66/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6768 - val_acc: 0.8452\n",
      "Epoch 67/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6867 - val_acc: 0.8536\n",
      "Epoch 68/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6932 - val_acc: 0.8452\n",
      "Epoch 69/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6719 - val_acc: 0.8536\n",
      "Epoch 70/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6940 - val_acc: 0.8494\n",
      "Epoch 71/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.6832 - val_acc: 0.8494\n",
      "Epoch 72/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.7293 - val_acc: 0.8494\n",
      "Epoch 73/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6856 - val_acc: 0.8494\n",
      "Epoch 74/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.7007 - val_acc: 0.8536\n",
      "Epoch 75/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6902 - val_acc: 0.8536\n",
      "Epoch 76/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6948 - val_acc: 0.8452\n",
      "Epoch 77/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6946 - val_acc: 0.8536\n",
      "Epoch 78/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6928 - val_acc: 0.8410\n",
      "Epoch 79/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.7044 - val_acc: 0.8494\n",
      "Epoch 80/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6939 - val_acc: 0.8536\n",
      "Epoch 81/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6969 - val_acc: 0.8536\n",
      "Epoch 82/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.7012 - val_acc: 0.8536\n",
      "Epoch 83/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.7031 - val_acc: 0.8536\n",
      "Epoch 84/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.7047 - val_acc: 0.8494\n",
      "Epoch 85/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.7071 - val_acc: 0.8536\n",
      "Epoch 86/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.7022 - val_acc: 0.8536\n",
      "Epoch 87/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.7088 - val_acc: 0.8536\n",
      "Epoch 88/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.7008 - val_acc: 0.8536\n",
      "Epoch 89/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.7007 - val_acc: 0.8536\n",
      "Epoch 90/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.7060 - val_acc: 0.8536\n",
      "Epoch 91/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.7065 - val_acc: 0.8536\n",
      "Epoch 92/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.7113 - val_acc: 0.8536\n",
      "Epoch 93/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.7021 - val_acc: 0.8536\n",
      "Epoch 94/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.7098 - val_acc: 0.8536\n",
      "Epoch 95/100\n",
      "716/716 [==============================] - 2s 2ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.7115 - val_acc: 0.8536\n",
      "Epoch 96/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.7134 - val_acc: 0.8536\n",
      "Epoch 97/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.7090 - val_acc: 0.8536\n",
      "Epoch 98/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.7152 - val_acc: 0.8536\n",
      "Epoch 99/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.7130 - val_acc: 0.8536\n",
      "Epoch 100/100\n",
      "716/716 [==============================] - 2s 3ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.7112 - val_acc: 0.8536\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape = (50,50,1), filters=52, kernel_size = RF_size, strides = stride, activation = 'relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(96, activation = 'relu'))\n",
    "model.add(Dense(39, activation = 'softmax'))\n",
    "model.compile(optimizer = optimizers.adam(lr = 0.0005), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x = inputs, validation_split = 0.25, y = labels, batch_size = 50, epochs = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
