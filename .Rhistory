learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
View(hidden.bias.weights)
hidden.bias.param.minus <- 0.1
hidden.bias.param.plus <- 0.001
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(runif(n.hidden, min=0, max=0), nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(runif(n.output, min=0,max=0.05), nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
display.learning.curves() #visualize learning by plotting weight similarity to alphabet input every 100 epochs
hidden.bias.param.minus <- 0.1
hidden.bias.param.plus <- 0.01
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(runif(n.hidden, min=0, max=0), nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(runif(n.output, min=0,max=0.05), nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
View(hidden.bias.weights)
hidden.bias.param.minus <- 0.5
hidden.bias.param.plus <- 0.01
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(runif(n.hidden, min=0, max=0), nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(runif(n.output, min=0,max=0.05), nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
hidden.bias.param.minus <- 1
hidden.bias.param.plus <- 0.01
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(runif(n.hidden, min=0, max=0), nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(runif(n.output, min=0,max=0.05), nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
View(hidden.bias.weights)
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
display.learning.curves() #visualize learning by plotting weight similarity to alphabet input every 100 epochs
View(hidden.bias.weights)
n.epochs <- 100
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(runif(n.hidden, min=0, max=0), nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(runif(n.output, min=0,max=0.05), nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
View(hidden.bias.weights)
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
View(hidden.bias.weights)
hidden.bias.param.plus <- 0.05
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(runif(n.hidden, min=0, max=0), nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(runif(n.output, min=0,max=0.05), nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
hidden.bias.param.plus <- 0.01
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
output.bias.weights <- matrix(0), nrow=n.output, ncol=1)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
trace.update <- function(input, input.hidden.weights, trace.hidden, hidden.bias.weights){
#trace.update <- function(input, input.hidden.weights, hidden.output.weights, trace.hidden, trace.output){
hidden <- forward.pass(input)
for(h in 1:n.hidden){
if(hidden[h] == 1){
hidden.bias.weights[h,1] <- hidden.bias.weights[h,1] - hidden.bias.param.minus
}
if(hidden[h] == 0){
hidden.bias.weights[h,1] <- hidden.bias.weights[h,1] + hidden.bias.param.plus
}
if(hidden.bias.weights[h,1] > 2){
hidden.bias.weights[h,1] <- 2
}
if(hidden.bias.weights[h,1] < -2){
hidden.bias.weights[h,1] <- -2
}
}
#forward.pass.results <- forward.pass(input)
#hidden <- forward.pass.results$hidden
#output <- forward.pass.results$output
for(i in 1:n.hidden){
trace.hidden[i] <- (1 - trace.param.hidden) * trace.hidden[i] + trace.param.hidden * hidden[i]
input.hidden.weights[,i] <- input.hidden.weights[,i] + learning.rate * trace.hidden[i] * (input - input.hidden.weights[,i])
}
return(list(trace.hidden = trace.hidden, input.hidden.weights = input.hidden.weights, hidden.bias.weights=hidden.bias.weights))
#for(b in 1:n.output){
#  trace.output <- (1 - trace.param.output) * trace.output[b] + trace.param.output * output[b]
#  hidden.output.weights[,b] <- hidden.output.weights[,b] + learning.rate * trace.output[i] * (hidden - hidden.output.weights[,b])
#}
#return(list(trace.hidden=trace.hidden, trace.ouput=trace.output, input.hidden.weights=input.hidden.weights, hidden.output.weights=hidden.output.weights, hidden.bias.weights=hidden.bias.weights, output.bias.weights=output.bias.weights))
}
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
View(hidden.bias.weights)
hidden.bias.param.plus <- 0.005
hidden.bias.param.minus <- 0.5
n.epochs <- 1000
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
hidden.bias.param.minus <- 0.05
hidden.bias.param.plus <- 0.005
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
View(hidden.bias.weights)
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
hidden.bias.param.minus <- 0.005
hidden.bias.param.plus <- 0.0005
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
hidden.bias.param.minus <- 0.0005
hidden.bias.param.plus <- 0.00005
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
View(hidden.bias.weights)
n.epochs <- 10000
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
View(hidden.bias.weights)
hidden.bias.param.minus <- 0.005
hidden.bias.param.plus <- 0.005
n.epochs <- 1000
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
display.learning.curves() #visualize learning by plotting weight similarity to alphabet input every 100 epochs
View(hidden.bias.weights)
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
hidden.bias.param.minus <- 0.05
hidden.bias.param.plus <- 0.05
hidden.bias.param.plus <- 0.005
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
View(hidden.bias.weights)
trace.update <- function(input, input.hidden.weights, trace.hidden, hidden.bias.weights){
#trace.update <- function(input, input.hidden.weights, hidden.output.weights, trace.hidden, trace.output){
hidden <- forward.pass(input)
for(h in 1:n.hidden){
if(hidden[h] == 1){
hidden.bias.weights[h,1] <- hidden.bias.weights[h,1] - hidden.bias.param.minus
}
if(hidden[h] == 0){
hidden.bias.weights[h,1] <- hidden.bias.weights[h,1] + hidden.bias.param.plus
}
if(hidden.bias.weights[h,1] > 5){
hidden.bias.weights[h,1] <- 5
}
if(hidden.bias.weights[h,1] < -5){
hidden.bias.weights[h,1] <- -5
}
}
#forward.pass.results <- forward.pass(input)
#hidden <- forward.pass.results$hidden
#output <- forward.pass.results$output
for(i in 1:n.hidden){
trace.hidden[i] <- (1 - trace.param.hidden) * trace.hidden[i] + trace.param.hidden * hidden[i]
input.hidden.weights[,i] <- input.hidden.weights[,i] + learning.rate * trace.hidden[i] * (input - input.hidden.weights[,i])
}
return(list(trace.hidden = trace.hidden, input.hidden.weights = input.hidden.weights, hidden.bias.weights=hidden.bias.weights))
#for(b in 1:n.output){
#  trace.output <- (1 - trace.param.output) * trace.output[b] + trace.param.output * output[b]
#  hidden.output.weights[,b] <- hidden.output.weights[,b] + learning.rate * trace.output[i] * (hidden - hidden.output.weights[,b])
#}
#return(list(trace.hidden=trace.hidden, trace.ouput=trace.output, input.hidden.weights=input.hidden.weights, hidden.output.weights=hidden.output.weights, hidden.bias.weights=hidden.bias.weights, output.bias.weights=output.bias.weights))
}
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
View(hidden.bias.weights)
hidden.bias.param.minus <- 0.01
hidden.bias.param.plus <- 0.005
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
hidden.bias.param.minus <- 0.05
View(hidden.bias.weights)
trace.update <- function(input, input.hidden.weights, trace.hidden, hidden.bias.weights){
#trace.update <- function(input, input.hidden.weights, hidden.output.weights, trace.hidden, trace.output){
hidden <- forward.pass(input)
for(h in 1:n.hidden){
if(hidden[h] == 1){
hidden.bias.weights[h,1] <- hidden.bias.weights[h,1] - hidden.bias.param.minus
}
if(hidden[h] == 0){
hidden.bias.weights[h,1] <- hidden.bias.weights[h,1] + hidden.bias.param.plus
}
if(hidden.bias.weights[h,1] > 25){
hidden.bias.weights[h,1] <- 25
}
if(hidden.bias.weights[h,1] < -25){
hidden.bias.weights[h,1] <- -25
}
}
#forward.pass.results <- forward.pass(input)
#hidden <- forward.pass.results$hidden
#output <- forward.pass.results$output
for(i in 1:n.hidden){
trace.hidden[i] <- (1 - trace.param.hidden) * trace.hidden[i] + trace.param.hidden * hidden[i]
input.hidden.weights[,i] <- input.hidden.weights[,i] + learning.rate * trace.hidden[i] * (input - input.hidden.weights[,i])
}
return(list(trace.hidden = trace.hidden, input.hidden.weights = input.hidden.weights, hidden.bias.weights=hidden.bias.weights))
#for(b in 1:n.output){
#  trace.output <- (1 - trace.param.output) * trace.output[b] + trace.param.output * output[b]
#  hidden.output.weights[,b] <- hidden.output.weights[,b] + learning.rate * trace.output[i] * (hidden - hidden.output.weights[,b])
#}
#return(list(trace.hidden=trace.hidden, trace.ouput=trace.output, input.hidden.weights=input.hidden.weights, hidden.output.weights=hidden.output.weights, hidden.bias.weights=hidden.bias.weights, output.bias.weights=output.bias.weights))
}
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
View(hidden.bias.weights)
hidden.bias.param.minus <- 0.1
hidden.bias.param.plus <- 0.05
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
View(hidden.bias.weights)
View(hidden.bias.weights)
hidden.bias.param.minus <- 0.001
hidden.bias.param.plus <- 0.0005
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
View(hidden.bias.weights)
hidden.bias.param.minus <- 0.01
hidden.bias.param.plus <- 0.005
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
trace.update <- function(input, input.hidden.weights, trace.hidden, hidden.bias.weights){
#trace.update <- function(input, input.hidden.weights, hidden.output.weights, trace.hidden, trace.output){
hidden <- forward.pass(input)
for(h in 1:n.hidden){
if(hidden[h] == 1){
hidden.bias.weights[h,1] <- hidden.bias.weights[h,1] - hidden.bias.param.minus
}
if(hidden[h] == 0){
hidden.bias.weights[h,1] <- hidden.bias.weights[h,1] + hidden.bias.param.plus
}
if(hidden.bias.weights[h,1] > 2){
hidden.bias.weights[h,1] <- 2
}
if(hidden.bias.weights[h,1] < -2){
hidden.bias.weights[h,1] <- -2
}
}
#forward.pass.results <- forward.pass(input)
#hidden <- forward.pass.results$hidden
#output <- forward.pass.results$output
for(i in 1:n.hidden){
trace.hidden[i] <- (1 - trace.param.hidden) * trace.hidden[i] + trace.param.hidden * hidden[i]
input.hidden.weights[,i] <- input.hidden.weights[,i] + learning.rate * trace.hidden[i] * (input - input.hidden.weights[,i])
}
return(list(trace.hidden = trace.hidden, input.hidden.weights = input.hidden.weights, hidden.bias.weights=hidden.bias.weights))
#for(b in 1:n.output){
#  trace.output <- (1 - trace.param.output) * trace.output[b] + trace.param.output * output[b]
#  hidden.output.weights[,b] <- hidden.output.weights[,b] + learning.rate * trace.output[i] * (hidden - hidden.output.weights[,b])
#}
#return(list(trace.hidden=trace.hidden, trace.ouput=trace.output, input.hidden.weights=input.hidden.weights, hidden.output.weights=hidden.output.weights, hidden.bias.weights=hidden.bias.weights, output.bias.weights=output.bias.weights))
}
source('~/GitHub/Int-Seg-Model/Spatial Pooling.R', echo=TRUE)
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
View(hidden.bias.weights)
hidden.bias.param.minus <- 0.1
hidden.bias.param.plus <- 0.005
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
display.learning.curves() #visualize learning by plotting weight similarity to alphabet input every 100 epochs
View(hidden.bias.weights)
hidden.bias.param.minus <- 0.01
hidden.bias.param.plus <- 0.001
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
View(hidden.bias.weights)
hidden.bias.param.minus <- 0.05
hidden.bias.param.plus <- 0.0005
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
output.storage <- function(){ #stores outputs
hidden.outputs <- matrix(0, nrow = n.test, ncol = n.hidden)
for(i in 1:26){
one.hidden <- forward.pass(alphabet[[i]])
hidden.outputs[i,] <- one.hidden
}
return(hidden.outputs)
}
display.learning.curves() #visualize learning by plotting weight similarity to alphabet input every 100 epochs
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
hidden.bias.param.minus <- 0.05
hidden.bias.param.plus <- 0.005
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
display.learning.curves() #visualize learning by plotting weight similarity to alphabet input every 100 epochs
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
View(hidden.bias.weights)
trace.update <- function(input, input.hidden.weights, trace.hidden, hidden.bias.weights){
#trace.update <- function(input, input.hidden.weights, hidden.output.weights, trace.hidden, trace.output){
hidden <- forward.pass(input)
for(h in 1:n.hidden){
if(hidden[h] == 1){
hidden.bias.weights[h,1] <- hidden.bias.weights[h,1] - hidden.bias.param.minus
}
if(hidden[h] == 0){
hidden.bias.weights[h,1] <- hidden.bias.weights[h,1] + hidden.bias.param.plus
}
if(hidden.bias.weights[h,1] > 1){
hidden.bias.weights[h,1] <- 1
}
if(hidden.bias.weights[h,1] < -1){
hidden.bias.weights[h,1] <- -1
}
}
#forward.pass.results <- forward.pass(input)
#hidden <- forward.pass.results$hidden
#output <- forward.pass.results$output
for(i in 1:n.hidden){
trace.hidden[i] <- (1 - trace.param.hidden) * trace.hidden[i] + trace.param.hidden * hidden[i]
input.hidden.weights[,i] <- input.hidden.weights[,i] + learning.rate * trace.hidden[i] * (input - input.hidden.weights[,i])
}
return(list(trace.hidden = trace.hidden, input.hidden.weights = input.hidden.weights, hidden.bias.weights=hidden.bias.weights))
#for(b in 1:n.output){
#  trace.output <- (1 - trace.param.output) * trace.output[b] + trace.param.output * output[b]
#  hidden.output.weights[,b] <- hidden.output.weights[,b] + learning.rate * trace.output[i] * (hidden - hidden.output.weights[,b])
#}
#return(list(trace.hidden=trace.hidden, trace.ouput=trace.output, input.hidden.weights=input.hidden.weights, hidden.output.weights=hidden.output.weights, hidden.bias.weights=hidden.bias.weights, output.bias.weights=output.bias.weights))
}
input.hidden.weights <- matrix(runif(n.input*n.hidden, min=0, max=0.05), nrow=n.input, ncol=n.hidden) #initialiize weights at random values between 0 and 0.05
hidden.bias.weights <- matrix(0, nrow=n.hidden, ncol=1)
hidden.output.weights <- matrix(runif(n.hidden*n.output, min=0, max=0.05), nrow=n.hidden, ncol=n.output)
output.bias.weights <- matrix(0, nrow=n.output, ncol=1)
learning.curve <- matrix(0, nrow = n.epochs/100, ncol = 26) #initializes learning data matrix
results <- batch(n.epochs) #run training batches
input.hidden.weights <- results$input.hidden.weights#save weights to global envirn.
hidden.bias.weights <- results$hidden.bias.weights
learning.curve <- results$learning.curve #save learning data to global envirn.
display.learning.curves() #visualize learning by plotting weight similarity to alphabet input every 100 epochs
display.learning.curves() #visualize learning by plotting weight similarity to alphabet input every 100 epochs
weight.images() #connection weight visualization by row (26). Letters will appear rotated 180 degrees.
