{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised ANNs for Mutual Information Investigation\n",
    "## Thomas Possidente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tom\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# ANN Building Imports\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import optimizers, losses\n",
    "from keras.engine.topology import Layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "\n",
    "# Standard Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Value Inits - Specify as needed\n",
    "num_inputs_per_batch = int(1000)  # number of dummy images in set\n",
    "size = int(16)          # Dimension of each dummy image should be size*size\n",
    "RF_size = int(4)        # Dimensions of the RF to be analyzed should be RF_size*RF_size\n",
    "\n",
    "# Value Inits - Leave these alone\n",
    "num_of_RFs = int((size*size) / (RF_size*RF_size))\n",
    "inputs_by_RF = np.empty([(num_inputs_per_batch * size), size])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pd.read_csv('test.csv')\n",
    "inputs = inputs.drop('X1', axis = 0) # Taking out col names\n",
    "inputs = inputs.apply(pd.to_numeric)  # converting to floats\n",
    "\n",
    "inputs = inputs.values # convert to np ndarray\n",
    "inputs = inputs.reshape(5000,16,16) # reshape to desired dims (5000 examples, 16*16)\n",
    "flattened_inputs = inputs.reshape(5000, 16*16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros(np.shape(flattened_inputs)[0])\n",
    "storage = np.zeros(np.shape(flattened_inputs))\n",
    "count = 0\n",
    "\n",
    "for i in range(np.shape(flattened_inputs)[0]):\n",
    "    if(~((flattened_inputs[i] == storage).all(1).any())):\n",
    "        labels[i] = count\n",
    "        storage[i] = flattened_inputs[i]\n",
    "        count += 1\n",
    "    elif((flattened_inputs[i] == storage).all(1).any()):\n",
    "        print(1)\n",
    "        label_index = np.where((flattened_inputs[i] == storage).all(1))\n",
    "        correct_label = labels[label_index]\n",
    "        storage[i] = flattened_inputs[i]\n",
    "        labels[i] = correct_label\n",
    "        \n",
    "labels = labels.astype(int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 4997, 4998, 4999])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Noise to Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape = (16,16,1), filters=4, kernel_size = (RF_size, RF_size), strides = RF_size, activation = 'relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizers.sgd(lr = 0.01), loss = 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x = inputs, y = , batch_size = , epochs = )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
